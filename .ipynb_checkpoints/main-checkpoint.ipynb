{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infrared-newfoundland",
   "metadata": {},
   "source": [
    "## Investigating the Zillow Housing Price Dataset\n",
    "\n",
    "N. Ranjan & R. Mattson | CSCI 6430* | Mar 11, 2021\n",
    "\n",
    "Total Runtime = 2mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "mental-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import zipfile\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-lightweight",
   "metadata": {},
   "source": [
    "###  Retrieve Data and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "impossible-kentucky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Data\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# https://drive.google.com/file/d/1ElIgZc8OTjxGcGsLHDfbTGPKLhknBqEV/view?usp=sharing\n",
    "\n",
    "url = \"https://docs.google.com/uc?export=download&id=1ElIgZc8OTjxGcGsLHDfbTGPKLhknBqEV\"\n",
    "urllib.request.urlretrieve(url, \"Data.zip\")\n",
    "with zipfile.ZipFile('Data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "print(\"Retrieved Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "impressive-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - get from google docs?? - We should!\n",
    "DF1B = pd.read_csv(r'data_minproj/City_MedianRentalPrice_1Bedroom.csv')\n",
    "DF2B = pd.read_csv(r'data_minproj/City_MedianRentalPrice_2Bedroom.csv')\n",
    "DF3B = pd.read_csv(r'data_minproj/City_MedianRentalPrice_3Bedroom.csv')\n",
    "DF4B = pd.read_csv(r'data_minproj/City_MedianRentalPrice_4Bedroom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "thick-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with useless information - These were only indexes\n",
    "DF1B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF2B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF3B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF4B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "everyday-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# record the number of bedrooms within the frame\n",
    "DF1B.insert(0, 'BedroomsSq', 1)\n",
    "DF2B.insert(0, 'BedroomsSq', 2)\n",
    "DF3B.insert(0, 'BedroomsSq', 3)\n",
    "DF4B.insert(0, 'BedroomsSq', 4)\n",
    "#BE CAREFUL WITH INSERTING BEDROOMS\n",
    "insertBedrooms = np.where(DF1B.columns=='2010-02')[0][0] \n",
    "print(int(insertBedrooms))\n",
    "DF1B.insert(int(insertBedrooms), 'Bedrooms', 1)\n",
    "DF2B.insert(int(insertBedrooms), 'Bedrooms', 2)\n",
    "DF3B.insert(int(insertBedrooms), 'Bedrooms', 3)\n",
    "DF4B.insert(int(insertBedrooms), 'Bedrooms', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "environmental-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [DF1B,DF2B,DF3B,DF4B]\n",
    "result = pd.concat(frames)\n",
    "result = result.sample(frac=1) #Shuffle!\n",
    "result = result.reset_index(drop=True) #Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ceramic-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BedroomsSq</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>2010-02</th>\n",
       "      <th>2010-03</th>\n",
       "      <th>2010-04</th>\n",
       "      <th>2010-05</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3367.5</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3399.5</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>OK</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>Tulsa County</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth-Arlington</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>1789.5</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1702.5</td>\n",
       "      <td>1715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>OK</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>Tulsa County</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1032.5</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1049.5</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>MA</td>\n",
       "      <td>Boston-Cambridge-Newton</td>\n",
       "      <td>Suffolk County</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>2097.5</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>2106.5</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>1</td>\n",
       "      <td>Port Orange</td>\n",
       "      <td>FL</td>\n",
       "      <td>Deltona-Daytona Beach-Ormond Beach</td>\n",
       "      <td>Volusia County</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1154.5</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1126.5</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>1315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>3</td>\n",
       "      <td>Oshkosh</td>\n",
       "      <td>WI</td>\n",
       "      <td>Oshkosh-Neenah</td>\n",
       "      <td>Winnebago County</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>987.5</td>\n",
       "      <td>985.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3</td>\n",
       "      <td>Loveland</td>\n",
       "      <td>CO</td>\n",
       "      <td>Fort Collins</td>\n",
       "      <td>Larimer County</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1744.5</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1762.5</td>\n",
       "      <td>1795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>1</td>\n",
       "      <td>Eden Prairie</td>\n",
       "      <td>MN</td>\n",
       "      <td>Minneapolis-St. Paul-Bloomington</td>\n",
       "      <td>Hennepin County</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>1342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4475.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3389 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BedroomsSq    RegionName State                                  Metro  \\\n",
       "0              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "1              1         Tulsa    OK                                  Tulsa   \n",
       "2              2        Dallas    TX            Dallas-Fort Worth-Arlington   \n",
       "3              3         Tulsa    OK                                  Tulsa   \n",
       "4              1       Chelsea    MA                Boston-Cambridge-Newton   \n",
       "...          ...           ...   ...                                    ...   \n",
       "3384           1   Port Orange    FL     Deltona-Daytona Beach-Ormond Beach   \n",
       "3385           3       Oshkosh    WI                         Oshkosh-Neenah   \n",
       "3386           3      Loveland    CO                           Fort Collins   \n",
       "3387           1  Eden Prairie    MN       Minneapolis-St. Paul-Bloomington   \n",
       "3388           2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "\n",
       "              CountyName  Bedrooms  2010-02  2010-03  2010-04  2010-05  ...  \\\n",
       "0     Los Angeles County         3      NaN      NaN      NaN      NaN  ...   \n",
       "1           Tulsa County         1      NaN      NaN      NaN      NaN  ...   \n",
       "2          Dallas County         2      NaN      NaN      NaN      NaN  ...   \n",
       "3           Tulsa County         3      NaN      NaN      NaN      NaN  ...   \n",
       "4         Suffolk County         1      NaN      NaN      NaN      NaN  ...   \n",
       "...                  ...       ...      ...      ...      ...      ...  ...   \n",
       "3384      Volusia County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3385    Winnebago County         3      NaN      NaN      NaN      NaN  ...   \n",
       "3386      Larimer County         3      NaN      NaN      NaN      NaN  ...   \n",
       "3387     Hennepin County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3388   Miami-Dade County         2      NaN      NaN      NaN      NaN  ...   \n",
       "\n",
       "      2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  \\\n",
       "0      3400.0   3367.5   3300.0   3399.5   3400.0   3425.0   3595.0   3500.0   \n",
       "1       635.0    675.0    695.0    705.0    790.0    765.0    775.0    765.0   \n",
       "2      1830.0   1850.0   1850.0   1810.0   1816.0   1789.5   1759.0   1731.0   \n",
       "3      1050.0    995.0    990.0   1025.0   1032.5   1010.0   1049.5   1075.0   \n",
       "4      1971.0   2097.5   2150.0   2198.0   2106.5   2076.0   2050.0   2010.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3384   1100.0   1135.0   1154.5   1214.0   1132.0   1126.5   1100.0   1285.0   \n",
       "3385   1000.0   1000.0   1000.0   1000.0    975.0    900.0    987.5    985.0   \n",
       "3386   1750.0   1744.5   1750.0   1750.0   1785.0   1750.0   1795.0   1750.0   \n",
       "3387   1514.0   1498.0   1515.0   1578.0   1535.0   1505.0   1470.0   1465.0   \n",
       "3388   4200.0   4200.0   4400.0   4400.0   4500.0   4500.0   4500.0   4475.0   \n",
       "\n",
       "      2019-11  2019-12  \n",
       "0      3550.0   3600.0  \n",
       "1       778.0    815.0  \n",
       "2      1702.5   1715.0  \n",
       "3      1100.0    995.0  \n",
       "4      2000.0   2000.0  \n",
       "...       ...      ...  \n",
       "3384   1285.0   1315.0  \n",
       "3385    900.0    900.0  \n",
       "3386   1762.5   1795.0  \n",
       "3387   1468.0   1342.0  \n",
       "3388   4400.0   4400.0  \n",
       "\n",
       "[3389 rows x 125 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "desirable-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(r'data_minproj/City_MedianRentalPrice_AllHomes_ALTERED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "official-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DF1B,DF2B,DF3B,DF4B\n",
    "del result,frames\n",
    "#Just saving memory, let's continue with our final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-minimum",
   "metadata": {},
   "source": [
    "### Preproccess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "composed-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(r'data_minproj/City_MedianRentalPrice_AllHomes_ALTERED.csv',index_col=0)\n",
    "# TrainDF = DF.iloc[:,:-1].copy() # Rest of the columns come here as training data\n",
    "# TestDF = DF.iloc[:,-1].copy()   # We predicting the last column\n",
    "# del DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "funky-sussex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    564\n",
       "FL    426\n",
       "TX    248\n",
       "GA    167\n",
       "VA    146\n",
       "MA    135\n",
       "WA    124\n",
       "IL    103\n",
       "MD    102\n",
       "NJ     98\n",
       "CO     82\n",
       "CT     79\n",
       "NC     79\n",
       "OH     76\n",
       "MI     75\n",
       "NY     74\n",
       "PA     70\n",
       "MN     52\n",
       "SC     52\n",
       "MO     49\n",
       "IN     46\n",
       "OR     43\n",
       "UT     37\n",
       "AZ     35\n",
       "KS     35\n",
       "IA     32\n",
       "OK     29\n",
       "LA     27\n",
       "TN     26\n",
       "WI     23\n",
       "RI     21\n",
       "HI     20\n",
       "NV     20\n",
       "AL     18\n",
       "KY     17\n",
       "ID     17\n",
       "NM     16\n",
       "MS     15\n",
       "ND     14\n",
       "AR     14\n",
       "MT     13\n",
       "DE     13\n",
       "NE     12\n",
       "WV     10\n",
       "AK      8\n",
       "NH      6\n",
       "SD      6\n",
       "DC      4\n",
       "ME      4\n",
       "WY      4\n",
       "VT      3\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST = DF['State'].value_counts()\n",
    "ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eleven-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb=LabelEncoder()\n",
    "lb.fit(DF['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "catholic-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RecordAnalysisDF = pd.DataFrame(columns=['RunNumber','Title','Algorithm','R2Mean','R2Median','RMSEMean','RMSEMedian']) #Will save results for later. You can keep running code below it and each time validation is run, results will be added here.\n",
    "runNo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "asian-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "isBedStateOptimized = True #Leave this as True.\n",
    "cut_off = 0.25 # if number of nulls > 25%, just remove the column.\n",
    "#We got lucky here as the null values always increased the further we go in the past "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "special-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0 829 800 771 741 695 621 571 510 465 412 361 306\n",
      " 249 209 144 107  60   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "['BedroomsSq' 'RegionName' 'State' 'Metro' 'CountyName' 'Bedrooms'\n",
      " '2017-08' '2017-09' '2017-10' '2017-11' '2017-12' '2018-01' '2018-02'\n",
      " '2018-03' '2018-04' '2018-05' '2018-06' '2018-07' '2018-08' '2018-09'\n",
      " '2018-10' '2018-11' '2018-12' '2019-01' '2019-02' '2019-03' '2019-04'\n",
      " '2019-05' '2019-06' '2019-07' '2019-08' '2019-09' '2019-10' '2019-11'\n",
      " '2019-12']\n"
     ]
    }
   ],
   "source": [
    "row_count = DF.index.size\n",
    "NullCountDF = pd.DataFrame({'Null_Count':DF.isnull().sum().to_numpy(),'Col_Name':DF.columns.to_numpy()})\n",
    "colsToKeep = NullCountDF[NullCountDF.Null_Count<=row_count*cut_off].Col_Name.to_numpy() #columns to keep,rest have too many nulls\n",
    "DF = DF[colsToKeep].copy() \n",
    "print(DF.isnull().sum().to_numpy())\n",
    "print(colsToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "otherwise-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Nulls\n",
    "def RemoveNulls(TheDF):\n",
    "   print('Removing Nulls...')\n",
    "   for col in TheDF.columns:\n",
    "      for x in TheDF[TheDF[col].isnull()].index: #Going through all columns\n",
    "         beds = TheDF.loc[x]['Bedrooms']\n",
    "         state = TheDF.loc[x]['State']\n",
    "         #print)\n",
    "         if(isBedStateOptimized == True):\n",
    "            valFill = TheDF[(TheDF['Bedrooms'] == beds) & (TheDF['State']==state)][col] #Bedroom and state\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill = TheDF[(TheDF['Bedrooms'] == beds)][col] #Check if we can do only with bedroom as this is more correlated than state\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill = TheDF[(TheDF['State'] == beds)][col] #If only bedrooms didnt work, try with State\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill =TheDF[col] #If we get null for those too..just take median of whole column\n",
    "            valFill = np.nanmedian(valFill)\n",
    "            TheDF.loc[x,col] = valFill\n",
    "         else:\n",
    "            valFill =TheDF[col]\n",
    "            valFill = np.nanmedian(valFill)\n",
    "            TheDF.loc[x,col] = valFill\n",
    "   print('Nulls Removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "generic-parent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Nulls...\n",
      "Nulls Removed.\n"
     ]
    }
   ],
   "source": [
    "RemoveNulls(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "preceding-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BedroomsSq</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>2019-10</th>\n",
       "      <th>2019-11</th>\n",
       "      <th>2019-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>3325.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3200.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3367.5</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3399.5</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3425.0</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3550.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>OK</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>Tulsa County</td>\n",
       "      <td>1</td>\n",
       "      <td>631.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>595.00</td>\n",
       "      <td>...</td>\n",
       "      <td>635.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth-Arlington</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>2</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>1786.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>1789.5</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>1702.5</td>\n",
       "      <td>1715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>OK</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>Tulsa County</td>\n",
       "      <td>3</td>\n",
       "      <td>937.5</td>\n",
       "      <td>925.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>975.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1032.5</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>1049.5</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>MA</td>\n",
       "      <td>Boston-Cambridge-Newton</td>\n",
       "      <td>Suffolk County</td>\n",
       "      <td>1</td>\n",
       "      <td>1784.5</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>1787.5</td>\n",
       "      <td>1745.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>2097.5</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>2106.5</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>1</td>\n",
       "      <td>Port Orange</td>\n",
       "      <td>FL</td>\n",
       "      <td>Deltona-Daytona Beach-Ormond Beach</td>\n",
       "      <td>Volusia County</td>\n",
       "      <td>1</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>1276.5</td>\n",
       "      <td>1240.5</td>\n",
       "      <td>1235.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1154.5</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1126.5</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>1315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>3</td>\n",
       "      <td>Oshkosh</td>\n",
       "      <td>WI</td>\n",
       "      <td>Oshkosh-Neenah</td>\n",
       "      <td>Winnebago County</td>\n",
       "      <td>3</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1247.5</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>987.5</td>\n",
       "      <td>985.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3</td>\n",
       "      <td>Loveland</td>\n",
       "      <td>CO</td>\n",
       "      <td>Fort Collins</td>\n",
       "      <td>Larimer County</td>\n",
       "      <td>3</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1662.5</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1744.5</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1762.5</td>\n",
       "      <td>1795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>1</td>\n",
       "      <td>Eden Prairie</td>\n",
       "      <td>MN</td>\n",
       "      <td>Minneapolis-St. Paul-Bloomington</td>\n",
       "      <td>Hennepin County</td>\n",
       "      <td>1</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>1127.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>1342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>4100.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4475.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3389 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BedroomsSq    RegionName State                                  Metro  \\\n",
       "0              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "1              1         Tulsa    OK                                  Tulsa   \n",
       "2              2        Dallas    TX            Dallas-Fort Worth-Arlington   \n",
       "3              3         Tulsa    OK                                  Tulsa   \n",
       "4              1       Chelsea    MA                Boston-Cambridge-Newton   \n",
       "...          ...           ...   ...                                    ...   \n",
       "3384           1   Port Orange    FL     Deltona-Daytona Beach-Ormond Beach   \n",
       "3385           3       Oshkosh    WI                         Oshkosh-Neenah   \n",
       "3386           3      Loveland    CO                           Fort Collins   \n",
       "3387           1  Eden Prairie    MN       Minneapolis-St. Paul-Bloomington   \n",
       "3388           2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "\n",
       "              CountyName  Bedrooms  2017-08  2017-09  2017-10  2017-11  ...  \\\n",
       "0     Los Angeles County         3   3325.0   3235.0   3300.0  3200.00  ...   \n",
       "1           Tulsa County         1    631.0    625.0    590.0   595.00  ...   \n",
       "2          Dallas County         2   1845.0   1795.0   1753.0  1786.00  ...   \n",
       "3           Tulsa County         3    937.5    925.0    925.0   975.00  ...   \n",
       "4         Suffolk County         1   1784.5   1903.0   1787.5  1745.00  ...   \n",
       "...                  ...       ...      ...      ...      ...      ...  ...   \n",
       "3384      Volusia County         1   1299.0   1276.5   1240.5  1235.75  ...   \n",
       "3385    Winnebago County         3   1200.0   1195.0   1247.5  1200.00  ...   \n",
       "3386      Larimer County         3   1595.0   1662.5   1645.0  1600.00  ...   \n",
       "3387     Hennepin County         1   1270.0   1155.0   1130.0  1127.50  ...   \n",
       "3388   Miami-Dade County         2   4100.0   4000.0   4100.0  4100.00  ...   \n",
       "\n",
       "      2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  \\\n",
       "0      3400.0   3367.5   3300.0   3399.5   3400.0   3425.0   3595.0   3500.0   \n",
       "1       635.0    675.0    695.0    705.0    790.0    765.0    775.0    765.0   \n",
       "2      1830.0   1850.0   1850.0   1810.0   1816.0   1789.5   1759.0   1731.0   \n",
       "3      1050.0    995.0    990.0   1025.0   1032.5   1010.0   1049.5   1075.0   \n",
       "4      1971.0   2097.5   2150.0   2198.0   2106.5   2076.0   2050.0   2010.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3384   1100.0   1135.0   1154.5   1214.0   1132.0   1126.5   1100.0   1285.0   \n",
       "3385   1000.0   1000.0   1000.0   1000.0    975.0    900.0    987.5    985.0   \n",
       "3386   1750.0   1744.5   1750.0   1750.0   1785.0   1750.0   1795.0   1750.0   \n",
       "3387   1514.0   1498.0   1515.0   1578.0   1535.0   1505.0   1470.0   1465.0   \n",
       "3388   4200.0   4200.0   4400.0   4400.0   4500.0   4500.0   4500.0   4475.0   \n",
       "\n",
       "      2019-11  2019-12  \n",
       "0      3550.0   3600.0  \n",
       "1       778.0    815.0  \n",
       "2      1702.5   1715.0  \n",
       "3      1100.0    995.0  \n",
       "4      2000.0   2000.0  \n",
       "...       ...      ...  \n",
       "3384   1285.0   1315.0  \n",
       "3385    900.0    900.0  \n",
       "3386   1762.5   1795.0  \n",
       "3387   1468.0   1342.0  \n",
       "3388   4400.0   4400.0  \n",
       "\n",
       "[3389 rows x 35 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "pressed-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed Last Column is Target, it should return Xtrain,Ytrain,Xtest,Ytest\n",
    "def ChangeDataSetForTimeSeries(TheDF):\n",
    "    \"\"\"\n",
    "    Uses a sliding window mechanism to convert a dataset into a timeseries model.\n",
    "    With T=10, we look at past 10 months data to predict the 11th month throughout the available     history of the dataset.\n",
    "    \"\"\"\n",
    "    posOfFirstDate = np.where(TheDF.columns=='Bedrooms')[0][0] + 1\n",
    "    FirstDate = TheDF.columns[posOfFirstDate]\n",
    "    T = 10\n",
    "    Startindex = np.where(TheDF.columns==FirstDate)[0][0]\n",
    "    #print(TheDF.columns[Startindex])\n",
    "    TrainEndindex = TheDF.columns.size-3\n",
    "    #ValidationEndindex = TheDF.columns.size-3\n",
    "    TestEndindex = TheDF.columns.size-2\n",
    "    #print(TheDF.columns[TrainEndindex])\n",
    "    size = TrainEndindex - Startindex + 1\n",
    "    colListTrain = TheDF.columns[0:Startindex].tolist()\n",
    "    for i in range(T):\n",
    "        colListTrain.append('T'+str(i))\n",
    "    TrainDFX = pd.DataFrame(columns=colListTrain[:-1])\n",
    "    TrainDFY = pd.DataFrame(columns=['T'+str(T)])\n",
    "    #print(colListTrain,len(colListTrain))\n",
    "    #Make Train-------------------------------\n",
    "    X_Arr = []\n",
    "    Y_Arr = []\n",
    "    for i in range(len(TheDF.index)): #Row Iteration\n",
    "        if(i%25==0):\n",
    "            print('\\r', 'Iteration', i+1, ' / Rows:', len(TheDF.index), end='')\n",
    "        initdataToInsert = TheDF.iloc[i,0:Startindex].to_numpy().tolist() #All our categorical data\n",
    "        #print('-')\n",
    "        #print(initdataToInsert)\n",
    "        #print('-')\n",
    "        for t in range(Startindex,TrainEndindex + 1 - T):\n",
    "            x = TheDF.iloc[i,t:t+T].to_numpy().tolist()\n",
    "            #print(x)\n",
    "            #x = np.concatenate((initdataToInsert,x))\n",
    "            X_Arr.extend(initdataToInsert)\n",
    "            X_Arr.extend(x)\n",
    "            y = TheDF.iloc[i,t+T]\n",
    "            Y_Arr.append(y)\n",
    "            #return X_Arr,Y_Arr\n",
    "        #--------Inefficient Garbage----------------\n",
    "        # X_Arr = np.array(X_Arr).reshape(-1,len(colListTrain))\n",
    "        # Y_Arr = np.array(Y_Arr).reshape(-1,1)\n",
    "        \n",
    "        # X_Arr = pd.DataFrame(X_Arr,columns=colListTrain).to_dict()\n",
    "        # Y_Arr = pd.DataFrame(Y_Arr,columns=['T10'])\n",
    "        # #print(X_Arr)\n",
    "        # TrainDFX = TrainDFX.append(X_Arr,ignore_index=True) #TOO SLOW IN A LOOP\n",
    "        # TrainDFY = TrainDFY.append(Y_Arr,ignore_index=True)\n",
    "        #break\n",
    "        #return TrainDFX,TrainDFY\n",
    "        #for ind in ():\n",
    "            #print(X)\n",
    "            #FinalDFX.loc[ind] = X[:,ind]\n",
    "            #FinalDFY.loc[ind] = Y.reshape(-1,1)\n",
    "            #break\n",
    "        #break   \n",
    "        # --------------------------    \n",
    "    print('\\r', 'Iteration', i+1, ' / Rows:', len(TheDF.index), end='') #Handy loading msg\n",
    "    X_Arr = np.array(X_Arr).reshape(-1,len(colListTrain)) #We had appended data in a single dimension array, time to get it back to a table form. (Unflatten)\n",
    "    Y_Arr = np.array(Y_Arr).reshape(-1,1)\n",
    "    \n",
    "    X_Arr = pd.DataFrame(X_Arr,columns=colListTrain)\n",
    "    Y_Arr = pd.DataFrame(Y_Arr,columns=['T10'])\n",
    "    #print(X_Arr)\n",
    "    TrainDFX = TrainDFX.append(X_Arr,ignore_index=True)\n",
    "    TrainDFY = TrainDFY.append(Y_Arr,ignore_index=True)\n",
    "    #Training Sets Done!!!!!\n",
    "    testColNames = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    #valColData = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    testColData = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    for i in range(T):\n",
    "        testColNames.append('T'+str(i))\n",
    "        #valColData.extend([TheDF.columns[ValidationEndindex-T+i+1]])\n",
    "        testColData.extend([TheDF.columns[TestEndindex-T+i+1]])\n",
    "    #Get Data for Testing.\n",
    "    print('----')\n",
    "    #print(valColData,testColData)\n",
    "    #ValDFX = TheDF[valColData].copy()\n",
    "    #ValDFX.columns = valAndTestColNames\n",
    "    #ValDFY = TheDF.iloc[:,ValidationEndindex+1].copy()\n",
    "    #ValDFY.columns = 'T'+str(T)\n",
    "    # ValidationEndindex\n",
    "    TestDFX = TheDF[testColData].copy()\n",
    "    TestDFX.columns = testColNames\n",
    "    TestDFY = TheDF.iloc[:,TestEndindex+1].copy()\n",
    "    TestDFY.columns = 'T'+str(T)\n",
    "    #return TrainDFX,TrainDFY,ValDFX,ValDFY,TestDFX,TestDFY\n",
    "    return TrainDFX,TrainDFY,TestDFX,TestDFY\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "polish-horizon",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 3389  / Rows: 3389----\n"
     ]
    }
   ],
   "source": [
    "TrainDFX,TrainDFY,TestDFX,TestDFY = ChangeDataSetForTimeSeries(DF) #Finally, got train and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "metallic-disposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BedroomsSq</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>3325.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3522.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3522.5</td>\n",
       "      <td>3440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3522.5</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>3</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3522.5</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3272.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57608</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57609</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57610</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57611</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57612</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Biscayne</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>2</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57613 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BedroomsSq    RegionName State                                  Metro  \\\n",
       "0              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "1              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "2              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "3              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "4              3      Pasadena    CA         Los Angeles-Long Beach-Anaheim   \n",
       "...          ...           ...   ...                                    ...   \n",
       "57608          2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "57609          2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "57610          2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "57611          2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "57612          2  Key Biscayne    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "\n",
       "               CountyName Bedrooms      T0      T1      T2      T3      T4  \\\n",
       "0      Los Angeles County        3  3325.0  3235.0  3300.0  3200.0  3400.0   \n",
       "1      Los Angeles County        3  3235.0  3300.0  3200.0  3400.0  3200.0   \n",
       "2      Los Angeles County        3  3300.0  3200.0  3400.0  3200.0  3000.0   \n",
       "3      Los Angeles County        3  3200.0  3400.0  3200.0  3000.0  3175.0   \n",
       "4      Los Angeles County        3  3400.0  3200.0  3000.0  3175.0  3500.0   \n",
       "...                   ...      ...     ...     ...     ...     ...     ...   \n",
       "57608   Miami-Dade County        2  4500.0  4500.0  4400.0  4375.0  4300.0   \n",
       "57609   Miami-Dade County        2  4500.0  4400.0  4375.0  4300.0  4200.0   \n",
       "57610   Miami-Dade County        2  4400.0  4375.0  4300.0  4200.0  4145.0   \n",
       "57611   Miami-Dade County        2  4375.0  4300.0  4200.0  4145.0  4200.0   \n",
       "57612   Miami-Dade County        2  4300.0  4200.0  4145.0  4200.0  4200.0   \n",
       "\n",
       "           T5      T6      T7      T8      T9  \n",
       "0      3200.0  3000.0  3175.0  3500.0  3500.0  \n",
       "1      3000.0  3175.0  3500.0  3500.0  3522.5  \n",
       "2      3175.0  3500.0  3500.0  3522.5  3440.0  \n",
       "3      3500.0  3500.0  3522.5  3440.0  3500.0  \n",
       "4      3500.0  3522.5  3440.0  3500.0  3272.5  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "57608  4200.0  4145.0  4200.0  4200.0  4400.0  \n",
       "57609  4145.0  4200.0  4200.0  4400.0  4400.0  \n",
       "57610  4200.0  4200.0  4400.0  4400.0  4500.0  \n",
       "57611  4200.0  4400.0  4400.0  4500.0  4500.0  \n",
       "57612  4400.0  4400.0  4500.0  4500.0  4500.0  \n",
       "\n",
       "[57613 rows x 16 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "intense-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DF #Save memory, also makes sure that i dont accidentally use this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "suitable-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "relative-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found out Bedroom was more correlated than these and then on 2nd place is State\n",
    "# TrainDF['RegionName'] = lb.fit_transform(TrainDF['RegionName'])\n",
    "# TrainDF['State'] = lb.fit_transform(TrainDF['State'])\n",
    "# TrainDF['Metro'] = lb.fit_transform(TrainDF['Metro'])\n",
    "# TrainDF['CountyName'] = lb.fit_transform(TrainDF['CountyName'])\n",
    "#TrainDF['State'] = lb.fit_transform(TrainDF['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "regulation-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainDF.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "balanced-greensboro",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Pass by Value Reference Magic!\n",
    "def AddStateSparseMatrix(TrainingDF):\n",
    "   \"\"\"\n",
    "   We are taking the State column and replacing it with 51 columns, (50 US states + DC).\n",
    "   \"\"\"\n",
    "   enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "   SM = enc.fit_transform(TrainingDF['State'].to_numpy().reshape(-1,1)) #Got it!\n",
    "   for ind,cat in zip(range(0,len(enc.categories_[0])),enc.categories_[0]):\n",
    "      TrainingDF.insert(0,'is'+str(cat),SM[:,ind]) # Inserted column names are isAK, isAL, isDC..etc. And it will contain 0 if that is not the state and 1 if that is the state\n",
    "   TrainingDF.drop(columns=['State'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-shopper",
   "metadata": {},
   "source": [
    "### Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "vertical-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAllModels(TrainDF,Output,title):\n",
    "    \"\"\"\n",
    "    Trains and validates data on multiple models\n",
    "    \"\"\"\n",
    "    global runNo\n",
    "    global RecordAnalysisDF\n",
    "    global isBedStateOptimized\n",
    "    def PrintMetrics(scores,algo):\n",
    "        \"\"\"\n",
    "        Internal Function\n",
    "        Used to print on console, nothing fancy here.\n",
    "        \"\"\"\n",
    "        global RecordAnalysisDF\n",
    "        print('-'*5)\n",
    "        meanR2 = np.absolute(scores['test_r2']).mean()\n",
    "        medianR2 = np.median(np.absolute(scores['test_r2']))\n",
    "        meanRMSE = np.absolute(scores['test_neg_root_mean_squared_error']).mean()\n",
    "        medianRMSE = np.median(np.absolute(scores['test_neg_root_mean_squared_error']))\n",
    "        meanMAPE = np.absolute(scores['test_neg_mean_absolute_percentage_error']).mean()\n",
    "        medianMAPE = np.median(np.absolute(scores['test_neg_mean_absolute_percentage_error']))\n",
    "        print('Average R2 score ', meanR2)\n",
    "        print('Median R2 score ', medianR2)\n",
    "        print('Average Root Mean Square Error ', meanRMSE)\n",
    "        print('Median Root Mean Square Error ', medianRMSE)\n",
    "        print('-'*5)\n",
    "        if(isBedStateOptimized==False):\n",
    "            algo = algo + ' Nulls removed with complete column'\n",
    "        RecordAnalysisDF = RecordAnalysisDF.append({'RunNumber':runNo,'Title':title,'Algorithm':algo,'R2Mean':meanR2,'R2Median':medianR2,'RMSEMean':meanRMSE,'RMSEMedian':medianRMSE},ignore_index=True)\n",
    "        #print('Average Mean Absolute Percentage Error ', meanMAPE)\n",
    "        #print('Median Mean Absolute Percentage Error ', medianMAPE)\n",
    "    #-----------------------Linear Regression---------------------------------------------\n",
    "    print(title)\n",
    "    print('-'*10)\n",
    "    print('Linear Regression')\n",
    "    model = make_pipeline(StandardScaler(),LinearRegression())\n",
    "    # Y_pred = model.predict(X_test)\n",
    "    # Y_pred = scY.inverse_transform(Y_pred)\n",
    "    # Y_test = scY.inverse_transform(Y_test)\n",
    "    scores = cross_validate(model, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    PrintMetrics(scores,'Linear Regression')#,meanMAPE,medianMAPE)\n",
    "    #----------------------------Polynomial Lasso amd Ridge-------------------------\n",
    "    for _,degree in enumerate([1]): #Couldn't do enumerate([1,2]) please do it if you have 10-15mins to spare and a powerful system. Tried it a few times, got bad scores so we decided to not do it.\n",
    "        polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Lasso(alpha=1e-2,max_iter=1e+6,tol=1e-2))\n",
    "        scores = cross_validate(polymodel, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "        print('Polynomial Degree with Lasso: '+str(degree))\n",
    "        PrintMetrics(scores,'Lasso Degree ' + str(degree))\n",
    "\n",
    "        polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Ridge(alpha=1e-3,max_iter=1e+6))\n",
    "        scores = cross_validate(polymodel, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "        print('Polynomial Degree with Ridge: '+str(degree))\n",
    "        PrintMetrics(scores,'Ridge Degree ' + str(degree))\n",
    "    #----------------------------DecisionTreeRegressor---------------------------------------\n",
    "    model = make_pipeline(StandardScaler(),DecisionTreeRegressor(max_depth=100))\n",
    "    scores = cross_validate(model, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    print('DecisionTreeRegressor')\n",
    "    PrintMetrics(scores,'DecisionTreeRegressor')\n",
    "    runNo = runNo + 1\n",
    "    print('-'*5)\n",
    "    print('-'*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-property",
   "metadata": {},
   "source": [
    "### Method 1: Drop all the Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "strategic-orange",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped Categorical Data\n",
      "----------\n",
      "Linear Regression\n",
      "-----\n",
      "Average R2 score  0.9730974811261773\n",
      "Median R2 score  0.992374082788784\n",
      "Average Root Mean Square Error  162.2488804564787\n",
      "Median Root Mean Square Error  134.4574906924478\n",
      "-----\n",
      "Polynomial Degree with Lasso: 1\n",
      "-----\n",
      "Average R2 score  0.9600462284755336\n",
      "Median R2 score  0.9909910587335871\n",
      "Average Root Mean Square Error  185.2965302060838\n",
      "Median Root Mean Square Error  144.84875111565083\n",
      "-----\n",
      "Polynomial Degree with Ridge: 1\n",
      "-----\n",
      "Average R2 score  0.9730974677084444\n",
      "Median R2 score  0.9923740829622943\n",
      "Average Root Mean Square Error  162.24887176933984\n",
      "Median Root Mean Square Error  134.45745400364285\n",
      "-----\n",
      "DecisionTreeRegressor\n",
      "-----\n",
      "Average R2 score  0.9493365336475993\n",
      "Median R2 score  0.9778266650027801\n",
      "Average Root Mean Square Error  269.3201892413738\n",
      "Median Root Mean Square Error  262.6280585089952\n",
      "-----\n",
      "-----\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "# RemoveNulls(FinalTrainDF,True)\n",
    "FinalTrainDF.drop(columns=['State'],inplace=True)\n",
    "RunAllModels(FinalTrainDF,TrainDFY,'Dropped Categorical Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-celebration",
   "metadata": {},
   "source": [
    "### Method2: Next, Let's change States to a sparse matrix and then to 51 columns, 1 for each State. Lets drop the other categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-oliver",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoded State,Removed Others\n",
      "----------\n",
      "Linear Regression\n",
      "-----\n",
      "Average R2 score  0.9731267266642429\n",
      "Median R2 score  0.9923985766868568\n",
      "Average Root Mean Square Error  162.19838304617844\n",
      "Median Root Mean Square Error  134.21129925399748\n",
      "-----\n",
      "Polynomial Degree with Lasso: 1\n",
      "-----\n",
      "Average R2 score  0.9600347989644227\n",
      "Median R2 score  0.9910198772510753\n",
      "Average Root Mean Square Error  185.35296546639927\n",
      "Median Root Mean Square Error  145.13844416632102\n",
      "-----\n",
      "Polynomial Degree with Ridge: 1\n",
      "-----\n",
      "Average R2 score  0.9731291586093312\n",
      "Median R2 score  0.9923987343667369\n",
      "Average Root Mean Square Error  162.19331667739908\n",
      "Median Root Mean Square Error  134.2119954513285\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#RemoveNulls(FinalTrainDF,True)\n",
    "AddStateSparseMatrix(FinalTrainDF)\n",
    "#FinalTrainDF.drop(columns=['State'],inplace=True)\n",
    "RunAllModels(FinalTrainDF,TrainDFY,'One Hot Encoded State,Removed Others')\n",
    "#FinalTrainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF.index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF.to_csv('RecordAnalysis.csv',index_label='S.No.') # Save to csv for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Analyzing this CSV File (Copy of the table is in the report), we found that \"One Hot Encoded State,Removed Others - NAN removed with column with Linear Regression\" had the least R2Mean and RMSE Median. So, it had performed best in the 2/4 metrics we considered. Hence, we decided to go ahead with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-memphis",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoded State,Removed Others\tLinear Regression\n",
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#RemoveNulls(FinalTrainDF,True)\n",
    "AddStateSparseMatrix(FinalTrainDF)\n",
    "FinalTestDF = TestDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#FinalTrainDF[ValDF.name] = ValDF\n",
    "#RemoveNulls(FinalTrainDF,False)\n",
    "AddStateSparseMatrix(FinalTestDF)\n",
    "#FinalTrainDF.drop(columns=['State'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "hist = model.fit(FinalTrainDF,TrainDFY)\n",
    "YPred = model.predict(FinalTestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2Score = r2score(TestDFY,YPred)\n",
    "RMSE = mse(TestDFY,YPred,squared=False)\n",
    "print('R2 score ', R2Score)\n",
    "print('Root Mean Square Error ', RMSE)\n",
    "print('Average of Output ',TestDFY.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bed in range(1,5):\n",
    "    filterArr = (FinalTestDF['Bedrooms'] == bed)\n",
    "    #print(filterArr)\n",
    "    print('For '+ str(bed) +' bedrooms')\n",
    "    print('-'*3)\n",
    "    R2Score = r2score(TestDFY[filterArr],YPred[filterArr])\n",
    "    RMSE = mse(TestDFY[filterArr],YPred[filterArr],squared=False)\n",
    "    print('R2 score ', R2Score)\n",
    "    print('Root Mean Square Error ', RMSE)\n",
    "    print('Average of '+ str(bed) +' Bedroom Cost ',TestDFY[filterArr].mean())\n",
    "    print('Number of Houses ',len(TestDFY[filterArr].index))\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
