{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF = pd.read_csv(r'Datasets\\City_MedianRentalPrice_AllHomes.csv')\n",
    "DF = pd.read_csv(r'Datasets/City_MedianRentalPrice_AllHomes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['RegionName', 'State', 'Metro', 'CountyName', 'Bedrooms',\n",
       "       '2010-02', '2010-03', '2010-04', '2010-05', '2010-06', '2010-07',\n",
       "       '2010-08', '2010-09', '2010-10', '2010-11', '2010-12', '2011-01',\n",
       "       '2011-02', '2011-03', '2011-04', '2011-05', '2011-06', '2011-07',\n",
       "       '2011-08', '2011-09', '2011-10', '2011-11', '2011-12', '2012-01',\n",
       "       '2012-02', '2012-03', '2012-04', '2012-05', '2012-06', '2012-07',\n",
       "       '2012-08', '2012-09', '2012-10', '2012-11', '2012-12', '2013-01',\n",
       "       '2013-02', '2013-03', '2013-04', '2013-05', '2013-06', '2013-07',\n",
       "       '2013-08', '2013-09', '2013-10', '2013-11', '2013-12', '2014-01',\n",
       "       '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07',\n",
       "       '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01',\n",
       "       '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07',\n",
       "       '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01',\n",
       "       '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07',\n",
       "       '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',\n",
       "       '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07',\n",
       "       '2017-08', '2017-09', '2017-10', '2017-11', '2017-12', '2018-01',\n",
       "       '2018-02', '2018-03', '2018-04', '2018-05', '2018-06', '2018-07',\n",
       "       '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01',\n",
       "       '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07',\n",
       "       '2019-08', '2019-09', '2019-10', '2019-11', '2019-12'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "DF.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Bedrooms'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "DF_Filt = DF.iloc[:,-20:-1]\n",
    "DF_Filt #Contains all numerical we want\n",
    "for x in DF_Filt.columns.to_numpy():\n",
    "   #sc = StandardScaler()\n",
    "   DF_Filt[x] = DF_Filt[x].values.reshape(-1,1)\n",
    "  \n",
    "DFLblColumns = DF.iloc[:,4:5]\n",
    "print(DFLblColumns.columns)\n",
    "for x in DFLblColumns.columns.to_numpy():\n",
    "   le = LabelEncoder() \n",
    "   DF_Filt[x] = le.fit_transform(DFLblColumns[x].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       2650.0\n",
       "1       2314.0\n",
       "2       1510.0\n",
       "3       1500.0\n",
       "4        855.0\n",
       "         ...  \n",
       "3384     935.0\n",
       "3385     757.0\n",
       "3386    1479.0\n",
       "3387    2041.0\n",
       "3388     864.5\n",
       "Name: 2019-12, Length: 3389, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "Y = DF.iloc[:,-1]\n",
    "# scY = StandardScaler()\n",
    "# Y = scY.fit_transform(Y.values.reshape(-1,1))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      2019-10  2019-11  Bedrooms\n",
       "0      2400.0   2595.0         1\n",
       "1      2315.0   2325.0         1\n",
       "2      1526.0   1535.0         2\n",
       "3      1595.0   1500.0         3\n",
       "4       850.0    850.0         1\n",
       "...       ...      ...       ...\n",
       "3384    924.0    925.0         0\n",
       "3385    785.0    770.0         1\n",
       "3386   1500.0   1467.0         0\n",
       "3387   2065.0   2053.0         1\n",
       "3388    869.0    869.0         1\n",
       "\n",
       "[3389 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2019-10</th>\n      <th>2019-11</th>\n      <th>Bedrooms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2400.0</td>\n      <td>2595.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2315.0</td>\n      <td>2325.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1526.0</td>\n      <td>1535.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1595.0</td>\n      <td>1500.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850.0</td>\n      <td>850.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>924.0</td>\n      <td>925.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>785.0</td>\n      <td>770.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>1500.0</td>\n      <td>1467.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>2065.0</td>\n      <td>2053.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>869.0</td>\n      <td>869.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3389 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X = DF_Filt\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2019-10     0\n2019-11     0\nBedrooms    0\ndtype: int64\n2019-10     0\n2019-11     0\nBedrooms    0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum())\n",
    "for col in X:\n",
    "    X.fillna(X[col].median(),inplace=True)\n",
    "    #X = X.fillna(X[col].median())\n",
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for train_index, test_index in skf.split(X, Y):\n",
    "#      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#      X_train, X_test = X[train_index], X[test_index]\n",
    "#      Y_train, Y_test = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(),LinearRegression())\n",
    "model_temp = LinearRegression() #TESTING\n",
    "hist = model_temp.fit(X,Y) #Testing\n",
    "# Y_pred = model.predict(X_test)\n",
    "# Y_pred = scY.inverse_transform(Y_pred)\n",
    "# Y_test = scY.inverse_transform(Y_test)\n",
    "scores = cross_validate(model, X, Y, cv=10,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "meanR2 = np.absolute(scores['test_r2']).mean()\n",
    "medianR2 = np.median(np.absolute(scores['test_r2']))\n",
    "meanRMSE = np.absolute(scores['test_neg_root_mean_squared_error']).mean()\n",
    "medianRMSE = np.median(np.absolute(scores['test_neg_root_mean_squared_error']))\n",
    "meanMAPE = np.absolute(scores['test_neg_mean_absolute_percentage_error']).mean()\n",
    "medianMAPE = np.median(np.absolute(scores['test_neg_mean_absolute_percentage_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0.01376881,   1.01536836, -10.1777158 ])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "model_temp.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['2019-10', '2019-11', 'Bedrooms'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average R2 score  0.9941740090619653\nMedian R2 score  0.9946362695912896\nAverage Root Mean Square Error  107.74573709033939\nMedian Root Mean Square Error  79.76682274405952\nAverage Mean Absolute Percentage Error  0.026279622175625173\nMedian Mean Absolute Percentage Error  0.026349299448344722\n"
     ]
    }
   ],
   "source": [
    "print('Average R2 score ',meanR2)\n",
    "print('Median R2 score ',medianR2)\n",
    "print('Average Root Mean Square Error ',meanRMSE)\n",
    "print('Median Root Mean Square Error ',medianRMSE)\n",
    "print('Average Mean Absolute Percentage Error ',meanMAPE)\n",
    "print('Median Mean Absolute Percentage Error ',medianMAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err = mse(Y_pred,Y_test,squared=False)\n",
    "# print(err)\n",
    "# print(Y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err2 = mape(Y_pred,Y_test)\n",
    "# print(err2)"
   ]
  },
  {
   "source": [
    "## Polynomial Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polymodel = Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression(fit_intercept=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----\n",
      "Polynomial Degree: 1\n",
      "-----\n",
      "Average R2 score  0.9941740155791103\n",
      "Median R2 score  0.9946362018844159\n",
      "Average Root Mean Square Error  107.74636413778265\n",
      "Median Root Mean Square Error  79.76655839853746\n",
      "Average Mean Absolute Percentage Error  0.02627945285353231\n",
      "Median Mean Absolute Percentage Error  0.026349134021083048\n",
      "----------\n",
      "-----\n",
      "Polynomial Degree: 2\n",
      "-----\n",
      "Average R2 score  0.9856704051222522\n",
      "Median R2 score  0.9935110925292738\n",
      "Average Root Mean Square Error  188.13803178806256\n",
      "Median Root Mean Square Error  76.09458046285846\n",
      "Average Mean Absolute Percentage Error  0.02473047463814586\n",
      "Median Mean Absolute Percentage Error  0.024261674724281278\n",
      "----------\n",
      "-----\n",
      "Polynomial Degree: 3\n",
      "-----\n",
      "Average R2 score  18.0767120758376\n",
      "Median R2 score  0.9927161965299236\n",
      "Average Root Mean Square Error  4032.755509113241\n",
      "Median Root Mean Square Error  95.33267903511799\n",
      "Average Mean Absolute Percentage Error  0.03059126571810731\n",
      "Median Mean Absolute Percentage Error  0.025537073677788943\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "for _,degree in enumerate([1,2,3]):\n",
    "    polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Ridge(alpha=1e-3))\n",
    "    scores = cross_validate(polymodel, X, Y, cv=10,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    print('-'*5)\n",
    "    print('Polynomial Degree: '+str(degree))\n",
    "    print('-'*5)\n",
    "    meanR2 = np.absolute(scores['test_r2']).mean()\n",
    "    medianR2 = np.median(np.absolute(scores['test_r2']))\n",
    "    meanRMSE = np.absolute(scores['test_neg_root_mean_squared_error']).mean()\n",
    "    medianRMSE = np.median(np.absolute(scores['test_neg_root_mean_squared_error']))\n",
    "    meanMAPE = np.absolute(scores['test_neg_mean_absolute_percentage_error']).mean()\n",
    "    medianMAPE = np.median(np.absolute(scores['test_neg_mean_absolute_percentage_error']))\n",
    "    print('Average R2 score ',meanR2)\n",
    "    print('Median R2 score ',medianR2)\n",
    "    print('Average Root Mean Square Error ',meanRMSE)\n",
    "    print('Median Root Mean Square Error ',medianRMSE)\n",
    "    print('Average Mean Absolute Percentage Error ',meanMAPE)\n",
    "    print('Median Mean Absolute Percentage Error ',medianMAPE)    \n",
    "    print('-'*10)\n",
    "# for count, degree in enumerate([2,3,4,5]):\n",
    "#     model = make_pipeline(PolynomialFeatures(degree), scY, Ridge(alpha=1e-3))\n",
    "#     model.fit(X_train, Y_train)\n",
    "#     Y_pred = model.predict(X_test)\n",
    "#     # err = mse(Y_pred,Y_test,squared=False)\n",
    "#     err = mape(Y_pred,Y_test)\n",
    "#     print(\"With degree of\", degree, \"the error is\", err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}