{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infrared-newfoundland",
   "metadata": {},
   "source": [
    "## Investigating the Zillow Housing Price Dataset\n",
    "\n",
    "N. Ranjan & R. Mattson | CSCI 6430* | Mar 11, 2021\n",
    "\n",
    "Total Runtime = 2mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mental-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-lightweight",
   "metadata": {},
   "source": [
    "###  Retrieve Data and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressive-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - get from google docs?? - We should!\n",
    "DF1B = pd.read_csv(r'Datasets/City_MedianRentalPrice_1Bedroom.csv')\n",
    "DF2B = pd.read_csv(r'Datasets/City_MedianRentalPrice_2Bedroom.csv')\n",
    "DF3B = pd.read_csv(r'Datasets/City_MedianRentalPrice_3Bedroom.csv')\n",
    "DF4B = pd.read_csv(r'Datasets/City_MedianRentalPrice_4Bedroom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thick-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with useless information - These were only indexes\n",
    "DF1B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF2B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF3B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF4B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# record the number of bedrooms within the frame\n",
    "DF1B.insert(0, 'BedroomsSq', 1)\n",
    "DF2B.insert(0, 'BedroomsSq', 2)\n",
    "DF3B.insert(0, 'BedroomsSq', 3)\n",
    "DF4B.insert(0, 'BedroomsSq', 4)\n",
    "#BE CAREFUL WITH INSERTING BEDROOMS\n",
    "insertBedrooms = np.where(DF1B.columns=='2010-02')[0][0] \n",
    "print(int(insertBedrooms))\n",
    "DF1B.insert(int(insertBedrooms), 'Bedrooms', 1)\n",
    "DF2B.insert(int(insertBedrooms), 'Bedrooms', 2)\n",
    "DF3B.insert(int(insertBedrooms), 'Bedrooms', 3)\n",
    "DF4B.insert(int(insertBedrooms), 'Bedrooms', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "environmental-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [DF1B,DF2B,DF3B,DF4B]\n",
    "result = pd.concat(frames)\n",
    "result = result.sample(frac=1) #Shuffle!\n",
    "result = result.reset_index(drop=True) #Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceramic-communication",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      BedroomsSq      RegionName State                             Metro  \\\n",
       "0              1     Mooresville    NC        Charlotte-Concord-Gastonia   \n",
       "1              2        Ferndale    MI           Detroit-Warren-Dearborn   \n",
       "2              1     San Leandro    CA     San Francisco-Oakland-Hayward   \n",
       "3              2  Farmers Branch    TX       Dallas-Fort Worth-Arlington   \n",
       "4              1          Malibu    CA    Los Angeles-Long Beach-Anaheim   \n",
       "...          ...             ...   ...                               ...   \n",
       "3384           3   Missouri City    TX  Houston-The Woodlands-Sugar Land   \n",
       "3385           1      Morgantown    WV                        Morgantown   \n",
       "3386           3       Grandview    MO                       Kansas City   \n",
       "3387           2         Fremont    CA     San Francisco-Oakland-Hayward   \n",
       "3388           4      Little Elm    TX       Dallas-Fort Worth-Arlington   \n",
       "\n",
       "              CountyName  Bedrooms  2010-02  2010-03  2010-04  2010-05  ...  \\\n",
       "0         Iredell County         1      NaN      NaN      NaN      NaN  ...   \n",
       "1         Oakland County         2      NaN      NaN      NaN      NaN  ...   \n",
       "2         Alameda County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3          Dallas County         2      NaN      NaN      NaN      NaN  ...   \n",
       "4     Los Angeles County         1      NaN      NaN      NaN      NaN  ...   \n",
       "...                  ...       ...      ...      ...      ...      ...  ...   \n",
       "3384    Fort Bend County         3      NaN      NaN      NaN      NaN  ...   \n",
       "3385   Monongalia County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3386      Jackson County         3      NaN      NaN      NaN      NaN  ...   \n",
       "3387      Alameda County         2      NaN      NaN      NaN      NaN  ...   \n",
       "3388       Denton County         4      NaN      NaN      NaN      NaN  ...   \n",
       "\n",
       "      2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  \\\n",
       "0       990.0   1020.0   1021.5   1040.0   1051.0   1039.5   1032.5   1027.5   \n",
       "1      1150.0   1149.0   1200.0   1200.0   1300.0   1350.0   1350.0   1350.0   \n",
       "2      1897.5   1950.0   1926.5   2075.0   1995.0   2125.0   1995.0   1924.0   \n",
       "3      1946.0   1947.0   1830.0   1735.0   1815.0   1815.0   1804.0   1859.5   \n",
       "4      4900.0   5000.0   5000.0   5000.0   5000.0   4900.0   5000.0   5000.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3384   1568.0   1595.0   1590.0   1600.0   1620.0   1600.0   1600.0   1600.0   \n",
       "3385    600.0    630.0    600.0    682.5    682.5    650.0    650.0    650.0   \n",
       "3386   1065.0   1045.0   1068.0   1012.5   1000.0   1065.0   1107.5   1157.5   \n",
       "3387   2725.0   2770.0   2800.0   2796.5   2750.0   2728.0   2700.0   2666.5   \n",
       "3388   1995.0   1997.5   2100.0   2099.5   2000.0   1897.5   1995.0   1995.0   \n",
       "\n",
       "      2019-11  2019-12  \n",
       "0      1030.0   1030.0  \n",
       "1      1272.5   1325.0  \n",
       "2      1925.5   1895.0  \n",
       "3      1935.0   1938.5  \n",
       "4      5000.0   5000.0  \n",
       "...       ...      ...  \n",
       "3384   1580.0   1599.5  \n",
       "3385    650.0    650.0  \n",
       "3386   1097.5   1147.5  \n",
       "3387   2651.0   2734.5  \n",
       "3388   1950.0   1950.0  \n",
       "\n",
       "[3389 rows x 125 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BedroomsSq</th>\n      <th>RegionName</th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>Bedrooms</th>\n      <th>2010-02</th>\n      <th>2010-03</th>\n      <th>2010-04</th>\n      <th>2010-05</th>\n      <th>...</th>\n      <th>2019-03</th>\n      <th>2019-04</th>\n      <th>2019-05</th>\n      <th>2019-06</th>\n      <th>2019-07</th>\n      <th>2019-08</th>\n      <th>2019-09</th>\n      <th>2019-10</th>\n      <th>2019-11</th>\n      <th>2019-12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>990.0</td>\n      <td>1020.0</td>\n      <td>1021.5</td>\n      <td>1040.0</td>\n      <td>1051.0</td>\n      <td>1039.5</td>\n      <td>1032.5</td>\n      <td>1027.5</td>\n      <td>1030.0</td>\n      <td>1030.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ferndale</td>\n      <td>MI</td>\n      <td>Detroit-Warren-Dearborn</td>\n      <td>Oakland County</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1150.0</td>\n      <td>1149.0</td>\n      <td>1200.0</td>\n      <td>1200.0</td>\n      <td>1300.0</td>\n      <td>1350.0</td>\n      <td>1350.0</td>\n      <td>1350.0</td>\n      <td>1272.5</td>\n      <td>1325.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>San Leandro</td>\n      <td>CA</td>\n      <td>San Francisco-Oakland-Hayward</td>\n      <td>Alameda County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1897.5</td>\n      <td>1950.0</td>\n      <td>1926.5</td>\n      <td>2075.0</td>\n      <td>1995.0</td>\n      <td>2125.0</td>\n      <td>1995.0</td>\n      <td>1924.0</td>\n      <td>1925.5</td>\n      <td>1895.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Farmers Branch</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Dallas County</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1946.0</td>\n      <td>1947.0</td>\n      <td>1830.0</td>\n      <td>1735.0</td>\n      <td>1815.0</td>\n      <td>1815.0</td>\n      <td>1804.0</td>\n      <td>1859.5</td>\n      <td>1935.0</td>\n      <td>1938.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Malibu</td>\n      <td>CA</td>\n      <td>Los Angeles-Long Beach-Anaheim</td>\n      <td>Los Angeles County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4900.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>4900.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>3</td>\n      <td>Missouri City</td>\n      <td>TX</td>\n      <td>Houston-The Woodlands-Sugar Land</td>\n      <td>Fort Bend County</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1568.0</td>\n      <td>1595.0</td>\n      <td>1590.0</td>\n      <td>1600.0</td>\n      <td>1620.0</td>\n      <td>1600.0</td>\n      <td>1600.0</td>\n      <td>1600.0</td>\n      <td>1580.0</td>\n      <td>1599.5</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>1</td>\n      <td>Morgantown</td>\n      <td>WV</td>\n      <td>Morgantown</td>\n      <td>Monongalia County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>600.0</td>\n      <td>630.0</td>\n      <td>600.0</td>\n      <td>682.5</td>\n      <td>682.5</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>650.0</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>3</td>\n      <td>Grandview</td>\n      <td>MO</td>\n      <td>Kansas City</td>\n      <td>Jackson County</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1065.0</td>\n      <td>1045.0</td>\n      <td>1068.0</td>\n      <td>1012.5</td>\n      <td>1000.0</td>\n      <td>1065.0</td>\n      <td>1107.5</td>\n      <td>1157.5</td>\n      <td>1097.5</td>\n      <td>1147.5</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>2</td>\n      <td>Fremont</td>\n      <td>CA</td>\n      <td>San Francisco-Oakland-Hayward</td>\n      <td>Alameda County</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2725.0</td>\n      <td>2770.0</td>\n      <td>2800.0</td>\n      <td>2796.5</td>\n      <td>2750.0</td>\n      <td>2728.0</td>\n      <td>2700.0</td>\n      <td>2666.5</td>\n      <td>2651.0</td>\n      <td>2734.5</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n      <td>2099.5</td>\n      <td>2000.0</td>\n      <td>1897.5</td>\n      <td>1995.0</td>\n      <td>1995.0</td>\n      <td>1950.0</td>\n      <td>1950.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3389 rows × 125 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv(r'Datasets\\City_MedianRentalPrice_AllHomes.csv')\n",
    "result.to_csv(r'Datasets/City_MedianRentalPrice_AllHomes_ALTERED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "official-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DF1B,DF2B,DF3B,DF4B\n",
    "del result,frames\n",
    "#Just saving memory, let's continue with our final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-minimum",
   "metadata": {},
   "source": [
    "### Preproccess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "composed-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF = pd.read_csv(r'Datasets\\City_MedianRentalPrice_AllHomes.csv')\n",
    "DF = pd.read_csv(r'Datasets/City_MedianRentalPrice_AllHomes_ALTERED.csv',index_col=0)\n",
    "# TrainDF = DF.iloc[:,:-1].copy() # Rest of the columns come here as training data\n",
    "# TestDF = DF.iloc[:,-1].copy()   # We predicting the last column\n",
    "# del DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CA    564\n",
       "FL    426\n",
       "TX    248\n",
       "GA    167\n",
       "VA    146\n",
       "MA    135\n",
       "WA    124\n",
       "IL    103\n",
       "MD    102\n",
       "NJ     98\n",
       "CO     82\n",
       "CT     79\n",
       "NC     79\n",
       "OH     76\n",
       "MI     75\n",
       "NY     74\n",
       "PA     70\n",
       "MN     52\n",
       "SC     52\n",
       "MO     49\n",
       "IN     46\n",
       "OR     43\n",
       "UT     37\n",
       "AZ     35\n",
       "KS     35\n",
       "IA     32\n",
       "OK     29\n",
       "LA     27\n",
       "TN     26\n",
       "WI     23\n",
       "RI     21\n",
       "NV     20\n",
       "HI     20\n",
       "AL     18\n",
       "KY     17\n",
       "ID     17\n",
       "NM     16\n",
       "MS     15\n",
       "ND     14\n",
       "AR     14\n",
       "DE     13\n",
       "MT     13\n",
       "NE     12\n",
       "WV     10\n",
       "AK      8\n",
       "NH      6\n",
       "SD      6\n",
       "WY      4\n",
       "ME      4\n",
       "DC      4\n",
       "VT      3\n",
       "Name: State, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ST = DF['State'].value_counts()\n",
    "ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "lb=LabelEncoder()\n",
    "lb.fit(DF['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RecordAnalysisDF = pd.DataFrame(columns=['RunNumber','Title','Algorithm','R2Mean','R2Median','RMSEMean','RMSEMedian']) #Will save results for later. You can keep running code below it and each time validation is run, results will be added here.\n",
    "runNo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "isBedStateOptimized = True #Leave this as True.\n",
    "cut_off = 0.25 # if number of nulls > 25%, just remove the column.\n",
    "#We got lucky here as the null values always increased the further we go in the past "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0   0   0   0   0 829 800 771 741 695 621 571 510 465 412 361 306\n 249 209 144 107  60   0   0   0   0   0   0   0   0   0   0   0   0]\n['BedroomsSq' 'RegionName' 'State' 'Metro' 'CountyName' 'Bedrooms'\n '2017-08' '2017-09' '2017-10' '2017-11' '2017-12' '2018-01' '2018-02'\n '2018-03' '2018-04' '2018-05' '2018-06' '2018-07' '2018-08' '2018-09'\n '2018-10' '2018-11' '2018-12' '2019-01' '2019-02' '2019-03' '2019-04'\n '2019-05' '2019-06' '2019-07' '2019-08' '2019-09' '2019-10' '2019-11'\n '2019-12']\n"
     ]
    }
   ],
   "source": [
    "row_count = DF.index.size\n",
    "NullCountDF = pd.DataFrame({'Null_Count':DF.isnull().sum().to_numpy(),'Col_Name':DF.columns.to_numpy()})\n",
    "colsToKeep = NullCountDF[NullCountDF.Null_Count<=row_count*cut_off].Col_Name.to_numpy() #columns to keep,rest have too many nulls\n",
    "DF = DF[colsToKeep].copy() \n",
    "print(DF.isnull().sum().to_numpy())\n",
    "print(colsToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Nulls\n",
    "def RemoveNulls(TheDF):\n",
    "   print('Removing Nulls...')\n",
    "   for col in TheDF.columns:\n",
    "      for x in TheDF[TheDF[col].isnull()].index: #Going through all columns\n",
    "         beds = TheDF.loc[x]['Bedrooms']\n",
    "         state = TheDF.loc[x]['State']\n",
    "         #print)\n",
    "         if(isBedStateOptimized == True):\n",
    "            valFill = TheDF[(TheDF['Bedrooms'] == beds) & (TheDF['State']==state)][col] #Bedroom and state\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill = TheDF[(TheDF['Bedrooms'] == beds)][col] #Check if we can do only with bedroom as this is more correlated than state\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill = TheDF[(TheDF['State'] == beds)][col] #If only bedrooms didnt work, try with State\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill =TheDF[col] #If we get null for those too..just take median of whole column\n",
    "            valFill = np.nanmedian(valFill)\n",
    "            TheDF.loc[x,col] = valFill\n",
    "         else:\n",
    "            valFill =TheDF[col]\n",
    "            valFill = np.nanmedian(valFill)\n",
    "            TheDF.loc[x,col] = valFill\n",
    "   print('Nulls Removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removing Nulls...\n",
      "Nulls Removed.\n"
     ]
    }
   ],
   "source": [
    "RemoveNulls(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      BedroomsSq      RegionName State                             Metro  \\\n",
       "0              1     Mooresville    NC        Charlotte-Concord-Gastonia   \n",
       "1              2        Ferndale    MI           Detroit-Warren-Dearborn   \n",
       "2              1     San Leandro    CA     San Francisco-Oakland-Hayward   \n",
       "3              2  Farmers Branch    TX       Dallas-Fort Worth-Arlington   \n",
       "4              1          Malibu    CA    Los Angeles-Long Beach-Anaheim   \n",
       "...          ...             ...   ...                               ...   \n",
       "3384           3   Missouri City    TX  Houston-The Woodlands-Sugar Land   \n",
       "3385           1      Morgantown    WV                        Morgantown   \n",
       "3386           3       Grandview    MO                       Kansas City   \n",
       "3387           2         Fremont    CA     San Francisco-Oakland-Hayward   \n",
       "3388           4      Little Elm    TX       Dallas-Fort Worth-Arlington   \n",
       "\n",
       "              CountyName  Bedrooms  2017-08  2017-09  2017-10  2017-11  ...  \\\n",
       "0         Iredell County         1   911.50    865.0    884.0    875.0  ...   \n",
       "1         Oakland County         2  1250.00   1270.0   1266.0   1237.0  ...   \n",
       "2         Alameda County         1  1700.00   1695.0   1722.5   1775.0  ...   \n",
       "3          Dallas County         2  1759.00   1672.0   1605.5   1641.0  ...   \n",
       "4     Los Angeles County         1  1795.00   1769.0   1794.0   1775.0  ...   \n",
       "...                  ...       ...      ...      ...      ...      ...  ...   \n",
       "3384    Fort Bend County         3  1550.00   1500.0   1500.0   1597.5  ...   \n",
       "3385   Monongalia County         1   586.25    670.0    650.0    595.0  ...   \n",
       "3386      Jackson County         3  1050.00   1050.0   1050.0   1050.0  ...   \n",
       "3387      Alameda County         2  2610.50   2600.0   2600.0   2600.0  ...   \n",
       "3388       Denton County         4  1900.00   1900.0   1895.0   1850.0  ...   \n",
       "\n",
       "      2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  \\\n",
       "0       990.0   1020.0   1021.5   1040.0   1051.0   1039.5   1032.5   1027.5   \n",
       "1      1150.0   1149.0   1200.0   1200.0   1300.0   1350.0   1350.0   1350.0   \n",
       "2      1897.5   1950.0   1926.5   2075.0   1995.0   2125.0   1995.0   1924.0   \n",
       "3      1946.0   1947.0   1830.0   1735.0   1815.0   1815.0   1804.0   1859.5   \n",
       "4      4900.0   5000.0   5000.0   5000.0   5000.0   4900.0   5000.0   5000.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3384   1568.0   1595.0   1590.0   1600.0   1620.0   1600.0   1600.0   1600.0   \n",
       "3385    600.0    630.0    600.0    682.5    682.5    650.0    650.0    650.0   \n",
       "3386   1065.0   1045.0   1068.0   1012.5   1000.0   1065.0   1107.5   1157.5   \n",
       "3387   2725.0   2770.0   2800.0   2796.5   2750.0   2728.0   2700.0   2666.5   \n",
       "3388   1995.0   1997.5   2100.0   2099.5   2000.0   1897.5   1995.0   1995.0   \n",
       "\n",
       "      2019-11  2019-12  \n",
       "0      1030.0   1030.0  \n",
       "1      1272.5   1325.0  \n",
       "2      1925.5   1895.0  \n",
       "3      1935.0   1938.5  \n",
       "4      5000.0   5000.0  \n",
       "...       ...      ...  \n",
       "3384   1580.0   1599.5  \n",
       "3385    650.0    650.0  \n",
       "3386   1097.5   1147.5  \n",
       "3387   2651.0   2734.5  \n",
       "3388   1950.0   1950.0  \n",
       "\n",
       "[3389 rows x 35 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BedroomsSq</th>\n      <th>RegionName</th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>Bedrooms</th>\n      <th>2017-08</th>\n      <th>2017-09</th>\n      <th>2017-10</th>\n      <th>2017-11</th>\n      <th>...</th>\n      <th>2019-03</th>\n      <th>2019-04</th>\n      <th>2019-05</th>\n      <th>2019-06</th>\n      <th>2019-07</th>\n      <th>2019-08</th>\n      <th>2019-09</th>\n      <th>2019-10</th>\n      <th>2019-11</th>\n      <th>2019-12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>911.50</td>\n      <td>865.0</td>\n      <td>884.0</td>\n      <td>875.0</td>\n      <td>...</td>\n      <td>990.0</td>\n      <td>1020.0</td>\n      <td>1021.5</td>\n      <td>1040.0</td>\n      <td>1051.0</td>\n      <td>1039.5</td>\n      <td>1032.5</td>\n      <td>1027.5</td>\n      <td>1030.0</td>\n      <td>1030.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ferndale</td>\n      <td>MI</td>\n      <td>Detroit-Warren-Dearborn</td>\n      <td>Oakland County</td>\n      <td>2</td>\n      <td>1250.00</td>\n      <td>1270.0</td>\n      <td>1266.0</td>\n      <td>1237.0</td>\n      <td>...</td>\n      <td>1150.0</td>\n      <td>1149.0</td>\n      <td>1200.0</td>\n      <td>1200.0</td>\n      <td>1300.0</td>\n      <td>1350.0</td>\n      <td>1350.0</td>\n      <td>1350.0</td>\n      <td>1272.5</td>\n      <td>1325.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>San Leandro</td>\n      <td>CA</td>\n      <td>San Francisco-Oakland-Hayward</td>\n      <td>Alameda County</td>\n      <td>1</td>\n      <td>1700.00</td>\n      <td>1695.0</td>\n      <td>1722.5</td>\n      <td>1775.0</td>\n      <td>...</td>\n      <td>1897.5</td>\n      <td>1950.0</td>\n      <td>1926.5</td>\n      <td>2075.0</td>\n      <td>1995.0</td>\n      <td>2125.0</td>\n      <td>1995.0</td>\n      <td>1924.0</td>\n      <td>1925.5</td>\n      <td>1895.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Farmers Branch</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Dallas County</td>\n      <td>2</td>\n      <td>1759.00</td>\n      <td>1672.0</td>\n      <td>1605.5</td>\n      <td>1641.0</td>\n      <td>...</td>\n      <td>1946.0</td>\n      <td>1947.0</td>\n      <td>1830.0</td>\n      <td>1735.0</td>\n      <td>1815.0</td>\n      <td>1815.0</td>\n      <td>1804.0</td>\n      <td>1859.5</td>\n      <td>1935.0</td>\n      <td>1938.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Malibu</td>\n      <td>CA</td>\n      <td>Los Angeles-Long Beach-Anaheim</td>\n      <td>Los Angeles County</td>\n      <td>1</td>\n      <td>1795.00</td>\n      <td>1769.0</td>\n      <td>1794.0</td>\n      <td>1775.0</td>\n      <td>...</td>\n      <td>4900.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>4900.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n      <td>5000.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>3</td>\n      <td>Missouri City</td>\n      <td>TX</td>\n      <td>Houston-The Woodlands-Sugar Land</td>\n      <td>Fort Bend County</td>\n      <td>3</td>\n      <td>1550.00</td>\n      <td>1500.0</td>\n      <td>1500.0</td>\n      <td>1597.5</td>\n      <td>...</td>\n      <td>1568.0</td>\n      <td>1595.0</td>\n      <td>1590.0</td>\n      <td>1600.0</td>\n      <td>1620.0</td>\n      <td>1600.0</td>\n      <td>1600.0</td>\n      <td>1600.0</td>\n      <td>1580.0</td>\n      <td>1599.5</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>1</td>\n      <td>Morgantown</td>\n      <td>WV</td>\n      <td>Morgantown</td>\n      <td>Monongalia County</td>\n      <td>1</td>\n      <td>586.25</td>\n      <td>670.0</td>\n      <td>650.0</td>\n      <td>595.0</td>\n      <td>...</td>\n      <td>600.0</td>\n      <td>630.0</td>\n      <td>600.0</td>\n      <td>682.5</td>\n      <td>682.5</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>650.0</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>3</td>\n      <td>Grandview</td>\n      <td>MO</td>\n      <td>Kansas City</td>\n      <td>Jackson County</td>\n      <td>3</td>\n      <td>1050.00</td>\n      <td>1050.0</td>\n      <td>1050.0</td>\n      <td>1050.0</td>\n      <td>...</td>\n      <td>1065.0</td>\n      <td>1045.0</td>\n      <td>1068.0</td>\n      <td>1012.5</td>\n      <td>1000.0</td>\n      <td>1065.0</td>\n      <td>1107.5</td>\n      <td>1157.5</td>\n      <td>1097.5</td>\n      <td>1147.5</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>2</td>\n      <td>Fremont</td>\n      <td>CA</td>\n      <td>San Francisco-Oakland-Hayward</td>\n      <td>Alameda County</td>\n      <td>2</td>\n      <td>2610.50</td>\n      <td>2600.0</td>\n      <td>2600.0</td>\n      <td>2600.0</td>\n      <td>...</td>\n      <td>2725.0</td>\n      <td>2770.0</td>\n      <td>2800.0</td>\n      <td>2796.5</td>\n      <td>2750.0</td>\n      <td>2728.0</td>\n      <td>2700.0</td>\n      <td>2666.5</td>\n      <td>2651.0</td>\n      <td>2734.5</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>1900.00</td>\n      <td>1900.0</td>\n      <td>1895.0</td>\n      <td>1850.0</td>\n      <td>...</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n      <td>2099.5</td>\n      <td>2000.0</td>\n      <td>1897.5</td>\n      <td>1995.0</td>\n      <td>1995.0</td>\n      <td>1950.0</td>\n      <td>1950.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3389 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed Last Column is Target, it should return Xtrain,Ytrain,Xtest,Ytest\n",
    "def ChangeDataSetForTimeSeries(TheDF):\n",
    "    \"\"\"\n",
    "    Uses a sliding window mechanism to convert a dataset into a timeseries model.\n",
    "    With T=10, we look at past 10 months data to predict the 11th month throughout the available     history of the dataset.\n",
    "    \"\"\"\n",
    "    posOfFirstDate = np.where(TheDF.columns=='Bedrooms')[0][0] + 1\n",
    "    FirstDate = TheDF.columns[posOfFirstDate]\n",
    "    T = 10\n",
    "    Startindex = np.where(TheDF.columns==FirstDate)[0][0]\n",
    "    #print(TheDF.columns[Startindex])\n",
    "    TrainEndindex = TheDF.columns.size-3\n",
    "    #ValidationEndindex = TheDF.columns.size-3\n",
    "    TestEndindex = TheDF.columns.size-2\n",
    "    #print(TheDF.columns[TrainEndindex])\n",
    "    size = TrainEndindex - Startindex + 1\n",
    "    colListTrain = TheDF.columns[0:Startindex].tolist()\n",
    "    for i in range(T):\n",
    "        colListTrain.append('T'+str(i))\n",
    "    TrainDFX = pd.DataFrame(columns=colListTrain[:-1])\n",
    "    TrainDFY = pd.DataFrame(columns=['T'+str(T)])\n",
    "    #print(colListTrain,len(colListTrain))\n",
    "    #Make Train-------------------------------\n",
    "    X_Arr = []\n",
    "    Y_Arr = []\n",
    "    for i in range(len(TheDF.index)): #Row Iteration\n",
    "        if(i%25==0):\n",
    "            print('\\r', 'Iteration', i+1, ' / Rows:', len(TheDF.index), end='')\n",
    "        initdataToInsert = TheDF.iloc[i,0:Startindex].to_numpy().tolist() #All our categorical data\n",
    "        #print('-')\n",
    "        #print(initdataToInsert)\n",
    "        #print('-')\n",
    "        for t in range(Startindex,TrainEndindex + 1 - T):\n",
    "            x = TheDF.iloc[i,t:t+T].to_numpy().tolist()\n",
    "            #print(x)\n",
    "            #x = np.concatenate((initdataToInsert,x))\n",
    "            X_Arr.extend(initdataToInsert)\n",
    "            X_Arr.extend(x)\n",
    "            y = TheDF.iloc[i,t+T]\n",
    "            Y_Arr.append(y)\n",
    "            #return X_Arr,Y_Arr\n",
    "        #--------Inefficient Garbage----------------\n",
    "        # X_Arr = np.array(X_Arr).reshape(-1,len(colListTrain))\n",
    "        # Y_Arr = np.array(Y_Arr).reshape(-1,1)\n",
    "        \n",
    "        # X_Arr = pd.DataFrame(X_Arr,columns=colListTrain).to_dict()\n",
    "        # Y_Arr = pd.DataFrame(Y_Arr,columns=['T10'])\n",
    "        # #print(X_Arr)\n",
    "        # TrainDFX = TrainDFX.append(X_Arr,ignore_index=True) #TOO SLOW IN A LOOP\n",
    "        # TrainDFY = TrainDFY.append(Y_Arr,ignore_index=True)\n",
    "        #break\n",
    "        #return TrainDFX,TrainDFY\n",
    "        #for ind in ():\n",
    "            #print(X)\n",
    "            #FinalDFX.loc[ind] = X[:,ind]\n",
    "            #FinalDFY.loc[ind] = Y.reshape(-1,1)\n",
    "            #break\n",
    "        #break   \n",
    "        # --------------------------    \n",
    "    print('\\r', 'Iteration', i+1, ' / Rows:', len(TheDF.index), end='') #Handy loading msg\n",
    "    X_Arr = np.array(X_Arr).reshape(-1,len(colListTrain)) #We had appended data in a single dimension array, time to get it back to a table form. (Unflatten)\n",
    "    Y_Arr = np.array(Y_Arr).reshape(-1,1)\n",
    "    \n",
    "    X_Arr = pd.DataFrame(X_Arr,columns=colListTrain)\n",
    "    Y_Arr = pd.DataFrame(Y_Arr,columns=['T10'])\n",
    "    #print(X_Arr)\n",
    "    TrainDFX = TrainDFX.append(X_Arr,ignore_index=True)\n",
    "    TrainDFY = TrainDFY.append(Y_Arr,ignore_index=True)\n",
    "    #Training Sets Done!!!!!\n",
    "    testColNames = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    #valColData = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    testColData = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    for i in range(T):\n",
    "        testColNames.append('T'+str(i))\n",
    "        #valColData.extend([TheDF.columns[ValidationEndindex-T+i+1]])\n",
    "        testColData.extend([TheDF.columns[TestEndindex-T+i+1]])\n",
    "    #Get Data for Testing.\n",
    "    print('----')\n",
    "    #print(valColData,testColData)\n",
    "    #ValDFX = TheDF[valColData].copy()\n",
    "    #ValDFX.columns = valAndTestColNames\n",
    "    #ValDFY = TheDF.iloc[:,ValidationEndindex+1].copy()\n",
    "    #ValDFY.columns = 'T'+str(T)\n",
    "    # ValidationEndindex\n",
    "    TestDFX = TheDF[testColData].copy()\n",
    "    TestDFX.columns = testColNames\n",
    "    TestDFY = TheDF.iloc[:,TestEndindex+1].copy()\n",
    "    TestDFY.columns = 'T'+str(T)\n",
    "    #return TrainDFX,TrainDFY,ValDFX,ValDFY,TestDFX,TestDFY\n",
    "    return TrainDFX,TrainDFY,TestDFX,TestDFY\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Iteration 3389  / Rows: 3389----\n"
     ]
    }
   ],
   "source": [
    "TrainDFX,TrainDFY,TestDFX,TestDFY = ChangeDataSetForTimeSeries(DF) #Finally, got train and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      BedroomsSq   RegionName State                        Metro  \\\n",
       "0              1  Mooresville    NC   Charlotte-Concord-Gastonia   \n",
       "1              1  Mooresville    NC   Charlotte-Concord-Gastonia   \n",
       "2              1  Mooresville    NC   Charlotte-Concord-Gastonia   \n",
       "3              1  Mooresville    NC   Charlotte-Concord-Gastonia   \n",
       "4              1  Mooresville    NC   Charlotte-Concord-Gastonia   \n",
       "...          ...          ...   ...                          ...   \n",
       "57608          4   Little Elm    TX  Dallas-Fort Worth-Arlington   \n",
       "57609          4   Little Elm    TX  Dallas-Fort Worth-Arlington   \n",
       "57610          4   Little Elm    TX  Dallas-Fort Worth-Arlington   \n",
       "57611          4   Little Elm    TX  Dallas-Fort Worth-Arlington   \n",
       "57612          4   Little Elm    TX  Dallas-Fort Worth-Arlington   \n",
       "\n",
       "           CountyName Bedrooms      T0      T1      T2      T3      T4  \\\n",
       "0      Iredell County        1   911.5   865.0   884.0   875.0   875.0   \n",
       "1      Iredell County        1   865.0   884.0   875.0   875.0   867.0   \n",
       "2      Iredell County        1   884.0   875.0   875.0   867.0   875.0   \n",
       "3      Iredell County        1   875.0   875.0   867.0   875.0   880.0   \n",
       "4      Iredell County        1   875.0   867.0   875.0   880.0   877.5   \n",
       "...               ...      ...     ...     ...     ...     ...     ...   \n",
       "57608   Denton County        4  1995.0  1947.5  1895.0  1900.0  1990.0   \n",
       "57609   Denton County        4  1947.5  1895.0  1900.0  1990.0  2000.0   \n",
       "57610   Denton County        4  1895.0  1900.0  1990.0  2000.0  2100.0   \n",
       "57611   Denton County        4  1900.0  1990.0  2000.0  2100.0  1995.0   \n",
       "57612   Denton County        4  1990.0  2000.0  2100.0  1995.0  1997.5   \n",
       "\n",
       "           T5      T6      T7      T8      T9  \n",
       "0       867.0   875.0   880.0   877.5   913.0  \n",
       "1       875.0   880.0   877.5   913.0   922.5  \n",
       "2       880.0   877.5   913.0   922.5   967.0  \n",
       "3       877.5   913.0   922.5   967.0   935.0  \n",
       "4       913.0   922.5   967.0   935.0   955.0  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "57608  2000.0  2100.0  1995.0  1997.5  2100.0  \n",
       "57609  2100.0  1995.0  1997.5  2100.0  2099.5  \n",
       "57610  1995.0  1997.5  2100.0  2099.5  2000.0  \n",
       "57611  1997.5  2100.0  2099.5  2000.0  1897.5  \n",
       "57612  2100.0  2099.5  2000.0  1897.5  1995.0  \n",
       "\n",
       "[57613 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BedroomsSq</th>\n      <th>RegionName</th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>Bedrooms</th>\n      <th>T0</th>\n      <th>T1</th>\n      <th>T2</th>\n      <th>T3</th>\n      <th>T4</th>\n      <th>T5</th>\n      <th>T6</th>\n      <th>T7</th>\n      <th>T8</th>\n      <th>T9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>911.5</td>\n      <td>865.0</td>\n      <td>884.0</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>867.0</td>\n      <td>875.0</td>\n      <td>880.0</td>\n      <td>877.5</td>\n      <td>913.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>865.0</td>\n      <td>884.0</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>867.0</td>\n      <td>875.0</td>\n      <td>880.0</td>\n      <td>877.5</td>\n      <td>913.0</td>\n      <td>922.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>884.0</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>867.0</td>\n      <td>875.0</td>\n      <td>880.0</td>\n      <td>877.5</td>\n      <td>913.0</td>\n      <td>922.5</td>\n      <td>967.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>867.0</td>\n      <td>875.0</td>\n      <td>880.0</td>\n      <td>877.5</td>\n      <td>913.0</td>\n      <td>922.5</td>\n      <td>967.0</td>\n      <td>935.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Mooresville</td>\n      <td>NC</td>\n      <td>Charlotte-Concord-Gastonia</td>\n      <td>Iredell County</td>\n      <td>1</td>\n      <td>875.0</td>\n      <td>867.0</td>\n      <td>875.0</td>\n      <td>880.0</td>\n      <td>877.5</td>\n      <td>913.0</td>\n      <td>922.5</td>\n      <td>967.0</td>\n      <td>935.0</td>\n      <td>955.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57608</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>1995.0</td>\n      <td>1947.5</td>\n      <td>1895.0</td>\n      <td>1900.0</td>\n      <td>1990.0</td>\n      <td>2000.0</td>\n      <td>2100.0</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n    </tr>\n    <tr>\n      <th>57609</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>1947.5</td>\n      <td>1895.0</td>\n      <td>1900.0</td>\n      <td>1990.0</td>\n      <td>2000.0</td>\n      <td>2100.0</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n      <td>2099.5</td>\n    </tr>\n    <tr>\n      <th>57610</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>1895.0</td>\n      <td>1900.0</td>\n      <td>1990.0</td>\n      <td>2000.0</td>\n      <td>2100.0</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n      <td>2099.5</td>\n      <td>2000.0</td>\n    </tr>\n    <tr>\n      <th>57611</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>1900.0</td>\n      <td>1990.0</td>\n      <td>2000.0</td>\n      <td>2100.0</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n      <td>2099.5</td>\n      <td>2000.0</td>\n      <td>1897.5</td>\n    </tr>\n    <tr>\n      <th>57612</th>\n      <td>4</td>\n      <td>Little Elm</td>\n      <td>TX</td>\n      <td>Dallas-Fort Worth-Arlington</td>\n      <td>Denton County</td>\n      <td>4</td>\n      <td>1990.0</td>\n      <td>2000.0</td>\n      <td>2100.0</td>\n      <td>1995.0</td>\n      <td>1997.5</td>\n      <td>2100.0</td>\n      <td>2099.5</td>\n      <td>2000.0</td>\n      <td>1897.5</td>\n      <td>1995.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57613 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "TrainDFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del DF #Save memory, also makes sure that i dont accidentally use this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found out Bedroom was more correlated than these and then on 2nd place is State\n",
    "# TrainDF['RegionName'] = lb.fit_transform(TrainDF['RegionName'])\n",
    "# TrainDF['State'] = lb.fit_transform(TrainDF['State'])\n",
    "# TrainDF['Metro'] = lb.fit_transform(TrainDF['Metro'])\n",
    "# TrainDF['CountyName'] = lb.fit_transform(TrainDF['CountyName'])\n",
    "#TrainDF['State'] = lb.fit_transform(TrainDF['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainDF.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "balanced-greensboro",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Pass by Value Reference Magic!\n",
    "def AddStateSparseMatrix(TrainingDF):\n",
    "   \"\"\"\n",
    "   We are taking the State column and replacing it with 51 columns, (50 US states + DC).\n",
    "   \"\"\"\n",
    "   enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "   SM = enc.fit_transform(TrainingDF['State'].to_numpy().reshape(-1,1)) #Got it!\n",
    "   for ind,cat in zip(range(0,len(enc.categories_[0])),enc.categories_[0]):\n",
    "      TrainingDF.insert(0,'is'+str(cat),SM[:,ind]) # Inserted column names are isAK, isAL, isDC..etc. And it will contain 0 if that is not the state and 1 if that is the state\n",
    "   TrainingDF.drop(columns=['State'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-shopper",
   "metadata": {},
   "source": [
    "### Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAllModels(TrainDF,Output,title):\n",
    "    \"\"\"\n",
    "    Trains and validates data on multiple models\n",
    "    \"\"\"\n",
    "    global runNo\n",
    "    global RecordAnalysisDF\n",
    "    global isBedStateOptimized\n",
    "    def PrintMetrics(scores,algo):\n",
    "        \"\"\"\n",
    "        Internal Function\n",
    "        Used to print on console, nothing fancy here.\n",
    "        \"\"\"\n",
    "        global RecordAnalysisDF\n",
    "        print('-'*5)\n",
    "        meanR2 = np.absolute(scores['test_r2']).mean()\n",
    "        medianR2 = np.median(np.absolute(scores['test_r2']))\n",
    "        meanRMSE = np.absolute(scores['test_neg_root_mean_squared_error']).mean()\n",
    "        medianRMSE = np.median(np.absolute(scores['test_neg_root_mean_squared_error']))\n",
    "        meanMAPE = np.absolute(scores['test_neg_mean_absolute_percentage_error']).mean()\n",
    "        medianMAPE = np.median(np.absolute(scores['test_neg_mean_absolute_percentage_error']))\n",
    "        print('Average R2 score ', meanR2)\n",
    "        print('Median R2 score ', medianR2)\n",
    "        print('Average Root Mean Square Error ', meanRMSE)\n",
    "        print('Median Root Mean Square Error ', medianRMSE)\n",
    "        print('-'*5)\n",
    "        if(isBedStateOptimized==False):\n",
    "            algo = algo + ' Nulls removed with complete column'\n",
    "        RecordAnalysisDF = RecordAnalysisDF.append({'RunNumber':runNo,'Title':title,'Algorithm':algo,'R2Mean':meanR2,'R2Median':medianR2,'RMSEMean':meanRMSE,'RMSEMedian':medianRMSE},ignore_index=True)\n",
    "        #print('Average Mean Absolute Percentage Error ', meanMAPE)\n",
    "        #print('Median Mean Absolute Percentage Error ', medianMAPE)\n",
    "    #-----------------------Linear Regression---------------------------------------------\n",
    "    print(title)\n",
    "    print('-'*10)\n",
    "    print('Linear Regression')\n",
    "    model = make_pipeline(StandardScaler(),LinearRegression())\n",
    "    # Y_pred = model.predict(X_test)\n",
    "    # Y_pred = scY.inverse_transform(Y_pred)\n",
    "    # Y_test = scY.inverse_transform(Y_test)\n",
    "    scores = cross_validate(model, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    PrintMetrics(scores,'Linear Regression')#,meanMAPE,medianMAPE)\n",
    "    #----------------------------Polynomial Lasso amd Ridge-------------------------\n",
    "    for _,degree in enumerate([1]): #Couldn't do enumerate([1,2]) please do it if you have 10-15mins to spare and a powerful system. Tried it a few times, got bad scores so we decided to not do it.\n",
    "        polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Lasso(alpha=1e-2,max_iter=1e+6,tol=1e-2))\n",
    "        scores = cross_validate(polymodel, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "        print('Polynomial Degree with Lasso: '+str(degree))\n",
    "        PrintMetrics(scores,'Lasso Degree ' + str(degree))\n",
    "\n",
    "        polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Ridge(alpha=1e-3,max_iter=1e+6))\n",
    "        scores = cross_validate(polymodel, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "        print('Polynomial Degree with Ridge: '+str(degree))\n",
    "        PrintMetrics(scores,'Ridge Degree ' + str(degree))\n",
    "    #----------------------------DecisionTreeRegressor---------------------------------------\n",
    "    model = make_pipeline(StandardScaler(),DecisionTreeRegressor(max_depth=100))\n",
    "    scores = cross_validate(model, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    print('DecisionTreeRegressor')\n",
    "    PrintMetrics(scores,'DecisionTreeRegressor')\n",
    "    runNo = runNo + 1\n",
    "    print('-'*5)\n",
    "    print('-'*15)"
   ]
  },
  {
   "source": [
    "### Method 1: Drop all the Categorical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropped Categorical Data\n",
      "----------\n",
      "Linear Regression\n",
      "-----\n",
      "Average R2 score  0.9744413955835195\n",
      "Median R2 score  0.9908098078832884\n",
      "Average Root Mean Square Error  157.3611320259808\n",
      "Median Root Mean Square Error  125.92456710445619\n",
      "-----\n",
      "Polynomial Degree with Lasso: 1\n",
      "-----\n",
      "Average R2 score  0.9620602686560296\n",
      "Median R2 score  0.9872678447400793\n",
      "Average Root Mean Square Error  180.9302802979508\n",
      "Median Root Mean Square Error  138.2863592994292\n",
      "-----\n",
      "Polynomial Degree with Ridge: 1\n",
      "-----\n",
      "Average R2 score  0.9744415702023288\n",
      "Median R2 score  0.9908099221224903\n",
      "Average Root Mean Square Error  157.36103438427259\n",
      "Median Root Mean Square Error  125.9261625593911\n",
      "-----\n",
      "DecisionTreeRegressor\n",
      "-----\n",
      "Average R2 score  0.9483884070891156\n",
      "Median R2 score  0.9793625126070374\n",
      "Average Root Mean Square Error  255.17971039953824\n",
      "Median Root Mean Square Error  202.78298355354622\n",
      "-----\n",
      "-----\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "# RemoveNulls(FinalTrainDF,True)\n",
    "FinalTrainDF.drop(columns=['State'],inplace=True)\n",
    "RunAllModels(FinalTrainDF,TrainDFY,'Dropped Categorical Data')"
   ]
  },
  {
   "source": [
    "### Method2: Next, Let's change States to a sparse matrix and then to 51 columns, 1 for each State. Lets drop the other categorical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "One Hot Encoded State,Removed Others\n",
      "----------\n",
      "Linear Regression\n",
      "-----\n",
      "Average R2 score  0.9744690111648431\n",
      "Median R2 score  0.9908048678324737\n",
      "Average Root Mean Square Error  157.32342214402595\n",
      "Median Root Mean Square Error  125.77333918637196\n",
      "-----\n",
      "Polynomial Degree with Lasso: 1\n",
      "-----\n",
      "Average R2 score  0.9621803812668402\n",
      "Median R2 score  0.9872781293151955\n",
      "Average Root Mean Square Error  180.8637223739935\n",
      "Median Root Mean Square Error  138.3461114326286\n",
      "-----\n",
      "Polynomial Degree with Ridge: 1\n",
      "-----\n",
      "Average R2 score  0.9744705270421042\n",
      "Median R2 score  0.9908070657918399\n",
      "Average Root Mean Square Error  157.3242197367044\n",
      "Median Root Mean Square Error  125.80284401256488\n",
      "-----\n",
      "DecisionTreeRegressor\n",
      "-----\n",
      "Average R2 score  0.9493479105193878\n",
      "Median R2 score  0.9790232787563821\n",
      "Average Root Mean Square Error  251.10436043858454\n",
      "Median Root Mean Square Error  188.1090834119632\n",
      "-----\n",
      "-----\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#RemoveNulls(FinalTrainDF,True)\n",
    "AddStateSparseMatrix(FinalTrainDF)\n",
    "#FinalTrainDF.drop(columns=['State'],inplace=True)\n",
    "RunAllModels(FinalTrainDF,TrainDFY,'One Hot Encoded State,Removed Others')\n",
    "#FinalTrainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  RunNumber                                 Title              Algorithm  \\\n",
       "0         1              Dropped Categorical Data      Linear Regression   \n",
       "1         1              Dropped Categorical Data         Lasso Degree 1   \n",
       "2         1              Dropped Categorical Data         Ridge Degree 1   \n",
       "3         1              Dropped Categorical Data  DecisionTreeRegressor   \n",
       "4         2  One Hot Encoded State,Removed Others      Linear Regression   \n",
       "5         2  One Hot Encoded State,Removed Others         Lasso Degree 1   \n",
       "6         2  One Hot Encoded State,Removed Others         Ridge Degree 1   \n",
       "7         2  One Hot Encoded State,Removed Others  DecisionTreeRegressor   \n",
       "\n",
       "     R2Mean  R2Median    RMSEMean  RMSEMedian  \n",
       "0  0.974441  0.990810  157.361132  125.924567  \n",
       "1  0.962060  0.987268  180.930280  138.286359  \n",
       "2  0.974442  0.990810  157.361034  125.926163  \n",
       "3  0.948388  0.979363  255.179710  202.782984  \n",
       "4  0.974469  0.990805  157.323422  125.773339  \n",
       "5  0.962180  0.987278  180.863722  138.346111  \n",
       "6  0.974471  0.990807  157.324220  125.802844  \n",
       "7  0.949348  0.979023  251.104360  188.109083  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RunNumber</th>\n      <th>Title</th>\n      <th>Algorithm</th>\n      <th>R2Mean</th>\n      <th>R2Median</th>\n      <th>RMSEMean</th>\n      <th>RMSEMedian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>Linear Regression</td>\n      <td>0.974441</td>\n      <td>0.990810</td>\n      <td>157.361132</td>\n      <td>125.924567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>Lasso Degree 1</td>\n      <td>0.962060</td>\n      <td>0.987268</td>\n      <td>180.930280</td>\n      <td>138.286359</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>Ridge Degree 1</td>\n      <td>0.974442</td>\n      <td>0.990810</td>\n      <td>157.361034</td>\n      <td>125.926163</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>DecisionTreeRegressor</td>\n      <td>0.948388</td>\n      <td>0.979363</td>\n      <td>255.179710</td>\n      <td>202.782984</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>Linear Regression</td>\n      <td>0.974469</td>\n      <td>0.990805</td>\n      <td>157.323422</td>\n      <td>125.773339</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>Lasso Degree 1</td>\n      <td>0.962180</td>\n      <td>0.987278</td>\n      <td>180.863722</td>\n      <td>138.346111</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>Ridge Degree 1</td>\n      <td>0.974471</td>\n      <td>0.990807</td>\n      <td>157.324220</td>\n      <td>125.802844</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>DecisionTreeRegressor</td>\n      <td>0.949348</td>\n      <td>0.979023</td>\n      <td>251.104360</td>\n      <td>188.109083</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "RecordAnalysisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF.index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF.to_csv('RecordAnalysis.csv',index_label='S.No.') # Save to csv for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Analyzing this CSV File (Copy of the table is in the report), we found that \"One Hot Encoded State,Removed Others - NAN removed with column with Linear Regression\" had the least R2Mean and RMSE Median. So, it had performed best in the 2/4 metrics we considered. Hence, we decided to go ahead with it."
   ]
  },
  {
   "source": [
    "### Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoded State,Removed Others\tLinear Regression\n",
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#RemoveNulls(FinalTrainDF,True)\n",
    "AddStateSparseMatrix(FinalTrainDF)\n",
    "FinalTestDF = TestDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#FinalTrainDF[ValDF.name] = ValDF\n",
    "#RemoveNulls(FinalTrainDF,False)\n",
    "AddStateSparseMatrix(FinalTestDF)\n",
    "#FinalTrainDF.drop(columns=['State'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "hist = model.fit(FinalTrainDF,TrainDFY)\n",
    "YPred = model.predict(FinalTestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 score  0.9944658263673406\nRoot Mean Square Error  136.35530883611855\nAverage of Output  1779.1479787547948\n"
     ]
    }
   ],
   "source": [
    "R2Score = r2score(TestDFY,YPred)\n",
    "RMSE = mse(TestDFY,YPred,squared=False)\n",
    "print('R2 score ', R2Score)\n",
    "print('Root Mean Square Error ', RMSE)\n",
    "print('Average of Output ',TestDFY.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For 1 bedrooms\n---\nR2 score  0.9913823922628504\nRoot Mean Square Error  49.1272876332863\nAverage of 1 Bedroom Cost  1384.4834963325184\nNumber of Houses  818\n----------\nFor 2 bedrooms\n---\nR2 score  0.9922283282885305\nRoot Mean Square Error  59.51255172112318\nAverage of 2 Bedroom Cost  1566.38814229249\nNumber of Houses  1265\n----------\nFor 3 bedrooms\n---\nR2 score  0.9963037370743136\nRoot Mean Square Error  96.81088377653744\nAverage of 3 Bedroom Cost  1969.8116161616163\nNumber of Houses  990\n----------\nFor 4 bedrooms\n---\nR2 score  0.9935542811880613\nRoot Mean Square Error  386.7985016699112\nAverage of 4 Bedroom Cost  3055.159810126582\nNumber of Houses  316\n----------\n"
     ]
    }
   ],
   "source": [
    "for bed in range(1,5):\n",
    "    filterArr = (FinalTestDF['Bedrooms'] == bed)\n",
    "    #print(filterArr)\n",
    "    print('For '+ str(bed) +' bedrooms')\n",
    "    print('-'*3)\n",
    "    R2Score = r2score(TestDFY[filterArr],YPred[filterArr])\n",
    "    RMSE = mse(TestDFY[filterArr],YPred[filterArr],squared=False)\n",
    "    print('R2 score ', R2Score)\n",
    "    print('Root Mean Square Error ', RMSE)\n",
    "    print('Average of '+ str(bed) +' Bedroom Cost ',TestDFY[filterArr].mean())\n",
    "    print('Number of Houses ',len(TestDFY[filterArr].index))\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}