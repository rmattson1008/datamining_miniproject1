{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infrared-newfoundland",
   "metadata": {},
   "source": [
    "## Investigating the Zillow Housing Price Dataset\n",
    "\n",
    "N. Ranjan & R. Mattson | CSCI 6430* | Mar 11, 2021\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TODO: \n",
    "- check file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mental-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-lightweight",
   "metadata": {},
   "source": [
    "###  Retrieve Data and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressive-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - get from google docs??\n",
    "DF1B = pd.read_csv(r'Datasets/City_MedianRentalPrice_1Bedroom.csv')\n",
    "DF2B = pd.read_csv(r'Datasets/City_MedianRentalPrice_2Bedroom.csv')\n",
    "DF3B = pd.read_csv(r'Datasets/City_MedianRentalPrice_3Bedroom.csv')\n",
    "DF4B = pd.read_csv(r'Datasets/City_MedianRentalPrice_4Bedroom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thick-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with useless information - These were only indexes\n",
    "DF1B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF2B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF3B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)\n",
    "DF4B.drop(columns=['SizeRank','Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# record the number of bedrooms within the frame\n",
    "DF1B.insert(0, 'BedroomsSq', 1)\n",
    "DF2B.insert(0, 'BedroomsSq', 2)\n",
    "DF3B.insert(0, 'BedroomsSq', 3)\n",
    "DF4B.insert(0, 'BedroomsSq', 4)\n",
    "#BE CAREFUL WITH INSERTING BEDROOMS\n",
    "insertBedrooms = np.where(DF1B.columns=='2010-02')[0][0] \n",
    "print(int(insertBedrooms))\n",
    "DF1B.insert(int(insertBedrooms), 'Bedrooms', 1)\n",
    "DF2B.insert(int(insertBedrooms), 'Bedrooms', 2)\n",
    "DF3B.insert(int(insertBedrooms), 'Bedrooms', 3)\n",
    "DF4B.insert(int(insertBedrooms), 'Bedrooms', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "environmental-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [DF1B,DF2B,DF3B,DF4B]\n",
    "result = pd.concat(frames)\n",
    "result = result.sample(frac=1) #Shuffle!\n",
    "result = result.reset_index(drop=True) #Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceramic-communication",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      BedroomsSq    RegionName State                                  Metro  \\\n",
       "0              2   Springfield    OH                            Springfield   \n",
       "1              4  Simpsonville    SC            Greenville-Anderson-Mauldin   \n",
       "2              2      Cranston    RI                     Providence-Warwick   \n",
       "3              1   Kansas City    KS                            Kansas City   \n",
       "4              4     Riverview    FL        Tampa-St. Petersburg-Clearwater   \n",
       "...          ...           ...   ...                                    ...   \n",
       "3384           2    Shrewsbury    MA                              Worcester   \n",
       "3385           1      Surfside    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "3386           1    Brookfield    WI          Milwaukee-Waukesha-West Allis   \n",
       "3387           1        Dedham    MA                Boston-Cambridge-Newton   \n",
       "3388           1       Wyoming    MI                   Grand Rapids-Wyoming   \n",
       "\n",
       "               CountyName  Bedrooms  2010-02  2010-03  2010-04  2010-05  ...  \\\n",
       "0            Clark County         2      NaN      NaN      NaN      NaN  ...   \n",
       "1       Greenville County         4      NaN      NaN      NaN      NaN  ...   \n",
       "2       Providence County         2      NaN      NaN      NaN      NaN  ...   \n",
       "3        Wyandotte County         1      NaN      NaN      NaN      NaN  ...   \n",
       "4     Hillsborough County         4      NaN      NaN      NaN      NaN  ...   \n",
       "...                   ...       ...      ...      ...      ...      ...  ...   \n",
       "3384     Worcester County         2      NaN      NaN      NaN      NaN  ...   \n",
       "3385    Miami-Dade County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3386      Waukesha County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3387       Norfolk County         1      NaN      NaN      NaN      NaN  ...   \n",
       "3388          Kent County         1      NaN      NaN      NaN      NaN  ...   \n",
       "\n",
       "      2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  \\\n",
       "0       665.0    685.0    714.0    714.0    685.0    695.0    697.5    675.0   \n",
       "1      1812.5   1770.0   1795.0   1795.0   1795.0   1695.0   1650.0   1695.0   \n",
       "2      1397.5   1397.5   1300.0   1200.0   1300.0   1350.0   1300.0   1300.0   \n",
       "3       830.5    863.0    747.0    744.0    785.0    735.0    705.0    785.0   \n",
       "4      1712.5   1750.0   1750.0   1750.0   1750.0   1750.0   1760.0   1750.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3384   1790.5   1890.0   1699.0   1727.5   1699.0   1725.0   1857.0   1867.0   \n",
       "3385   1875.0   1850.0   1750.0   1800.0   1800.0   1750.0   1750.0   1800.0   \n",
       "3386   1385.0   1385.0   1386.0   1386.0   1395.0   1405.0   1365.0   1395.0   \n",
       "3387   2392.5   2345.0   2347.5   2347.5   2343.5   2433.0   2334.5   1985.0   \n",
       "3388    828.5    838.0    844.0    858.0    876.5    891.0    882.0    884.5   \n",
       "\n",
       "      2019-11  2019-12  \n",
       "0       650.0    675.0  \n",
       "1      1800.0   1850.0  \n",
       "2      1200.0   1250.0  \n",
       "3       747.5    695.0  \n",
       "4      1752.5   1745.0  \n",
       "...       ...      ...  \n",
       "3384   1701.5   1762.0  \n",
       "3385   1800.0   1850.0  \n",
       "3386   1395.0   1395.0  \n",
       "3387   1950.0   1725.0  \n",
       "3388    869.0    924.0  \n",
       "\n",
       "[3389 rows x 125 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BedroomsSq</th>\n      <th>RegionName</th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>Bedrooms</th>\n      <th>2010-02</th>\n      <th>2010-03</th>\n      <th>2010-04</th>\n      <th>2010-05</th>\n      <th>...</th>\n      <th>2019-03</th>\n      <th>2019-04</th>\n      <th>2019-05</th>\n      <th>2019-06</th>\n      <th>2019-07</th>\n      <th>2019-08</th>\n      <th>2019-09</th>\n      <th>2019-10</th>\n      <th>2019-11</th>\n      <th>2019-12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>665.0</td>\n      <td>685.0</td>\n      <td>714.0</td>\n      <td>714.0</td>\n      <td>685.0</td>\n      <td>695.0</td>\n      <td>697.5</td>\n      <td>675.0</td>\n      <td>650.0</td>\n      <td>675.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Simpsonville</td>\n      <td>SC</td>\n      <td>Greenville-Anderson-Mauldin</td>\n      <td>Greenville County</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1812.5</td>\n      <td>1770.0</td>\n      <td>1795.0</td>\n      <td>1795.0</td>\n      <td>1795.0</td>\n      <td>1695.0</td>\n      <td>1650.0</td>\n      <td>1695.0</td>\n      <td>1800.0</td>\n      <td>1850.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Cranston</td>\n      <td>RI</td>\n      <td>Providence-Warwick</td>\n      <td>Providence County</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1397.5</td>\n      <td>1397.5</td>\n      <td>1300.0</td>\n      <td>1200.0</td>\n      <td>1300.0</td>\n      <td>1350.0</td>\n      <td>1300.0</td>\n      <td>1300.0</td>\n      <td>1200.0</td>\n      <td>1250.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Kansas City</td>\n      <td>KS</td>\n      <td>Kansas City</td>\n      <td>Wyandotte County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>830.5</td>\n      <td>863.0</td>\n      <td>747.0</td>\n      <td>744.0</td>\n      <td>785.0</td>\n      <td>735.0</td>\n      <td>705.0</td>\n      <td>785.0</td>\n      <td>747.5</td>\n      <td>695.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Riverview</td>\n      <td>FL</td>\n      <td>Tampa-St. Petersburg-Clearwater</td>\n      <td>Hillsborough County</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1712.5</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1760.0</td>\n      <td>1750.0</td>\n      <td>1752.5</td>\n      <td>1745.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>2</td>\n      <td>Shrewsbury</td>\n      <td>MA</td>\n      <td>Worcester</td>\n      <td>Worcester County</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1790.5</td>\n      <td>1890.0</td>\n      <td>1699.0</td>\n      <td>1727.5</td>\n      <td>1699.0</td>\n      <td>1725.0</td>\n      <td>1857.0</td>\n      <td>1867.0</td>\n      <td>1701.5</td>\n      <td>1762.0</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>1</td>\n      <td>Surfside</td>\n      <td>FL</td>\n      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n      <td>Miami-Dade County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1875.0</td>\n      <td>1850.0</td>\n      <td>1750.0</td>\n      <td>1800.0</td>\n      <td>1800.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1800.0</td>\n      <td>1800.0</td>\n      <td>1850.0</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>1</td>\n      <td>Brookfield</td>\n      <td>WI</td>\n      <td>Milwaukee-Waukesha-West Allis</td>\n      <td>Waukesha County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1385.0</td>\n      <td>1385.0</td>\n      <td>1386.0</td>\n      <td>1386.0</td>\n      <td>1395.0</td>\n      <td>1405.0</td>\n      <td>1365.0</td>\n      <td>1395.0</td>\n      <td>1395.0</td>\n      <td>1395.0</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>1</td>\n      <td>Dedham</td>\n      <td>MA</td>\n      <td>Boston-Cambridge-Newton</td>\n      <td>Norfolk County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2392.5</td>\n      <td>2345.0</td>\n      <td>2347.5</td>\n      <td>2347.5</td>\n      <td>2343.5</td>\n      <td>2433.0</td>\n      <td>2334.5</td>\n      <td>1985.0</td>\n      <td>1950.0</td>\n      <td>1725.0</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n      <td>858.0</td>\n      <td>876.5</td>\n      <td>891.0</td>\n      <td>882.0</td>\n      <td>884.5</td>\n      <td>869.0</td>\n      <td>924.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3389 rows × 125 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv(r'Datasets\\City_MedianRentalPrice_AllHomes.csv')\n",
    "result.to_csv(r'Datasets/City_MedianRentalPrice_AllHomes_ALTERED.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "official-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DF1B,DF2B,DF3B,DF4B\n",
    "del result,frames\n",
    "#Just saving memory, let's continue with our final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-minimum",
   "metadata": {},
   "source": [
    "### Preproccess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "composed-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF = pd.read_csv(r'Datasets\\City_MedianRentalPrice_AllHomes.csv')\n",
    "DF = pd.read_csv(r'Datasets/City_MedianRentalPrice_AllHomes_ALTERED.csv',index_col=0)\n",
    "# TrainDF = DF.iloc[:,:-1].copy() # Rest of the columns come here as training data\n",
    "# TestDF = DF.iloc[:,-1].copy()   # We predicting the last column\n",
    "# del DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CA    564\n",
       "FL    426\n",
       "TX    248\n",
       "GA    167\n",
       "VA    146\n",
       "MA    135\n",
       "WA    124\n",
       "IL    103\n",
       "MD    102\n",
       "NJ     98\n",
       "CO     82\n",
       "NC     79\n",
       "CT     79\n",
       "OH     76\n",
       "MI     75\n",
       "NY     74\n",
       "PA     70\n",
       "MN     52\n",
       "SC     52\n",
       "MO     49\n",
       "IN     46\n",
       "OR     43\n",
       "UT     37\n",
       "AZ     35\n",
       "KS     35\n",
       "IA     32\n",
       "OK     29\n",
       "LA     27\n",
       "TN     26\n",
       "WI     23\n",
       "RI     21\n",
       "HI     20\n",
       "NV     20\n",
       "AL     18\n",
       "ID     17\n",
       "KY     17\n",
       "NM     16\n",
       "MS     15\n",
       "AR     14\n",
       "ND     14\n",
       "MT     13\n",
       "DE     13\n",
       "NE     12\n",
       "WV     10\n",
       "AK      8\n",
       "NH      6\n",
       "SD      6\n",
       "ME      4\n",
       "DC      4\n",
       "WY      4\n",
       "VT      3\n",
       "Name: State, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ST = DF['State'].value_counts()\n",
    "ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "lb=LabelEncoder()\n",
    "lb.fit(DF['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RecordAnalysisDF = pd.DataFrame(columns=['RunNumber','Title','Algorithm','R2Mean','R2Median','RMSEMean','RMSEMedian']) #Will save results for later\n",
    "runNo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "isBedStateOptimized = True #LEAVE THIS TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  0   0   0   0   0   0 829 800 771 741 695 621 571 510 465 412 361 306\n 249 209 144 107  60   0   0   0   0   0   0   0   0   0   0   0   0]\n['BedroomsSq' 'RegionName' 'State' 'Metro' 'CountyName' 'Bedrooms'\n '2017-08' '2017-09' '2017-10' '2017-11' '2017-12' '2018-01' '2018-02'\n '2018-03' '2018-04' '2018-05' '2018-06' '2018-07' '2018-08' '2018-09'\n '2018-10' '2018-11' '2018-12' '2019-01' '2019-02' '2019-03' '2019-04'\n '2019-05' '2019-06' '2019-07' '2019-08' '2019-09' '2019-10' '2019-11'\n '2019-12']\n"
     ]
    }
   ],
   "source": [
    "cut_off = 0.25 # if number of nulls > 25%, just remove the column.\n",
    "#We got lucky here as the null values always increased the further we go in the past \n",
    "row_count = DF.index.size\n",
    "NullCountDF = pd.DataFrame({'Null_Count':DF.isnull().sum().to_numpy(),'Col_Name':DF.columns.to_numpy()})\n",
    "colsToKeep = NullCountDF[NullCountDF.Null_Count<=row_count*cut_off].Col_Name.to_numpy() #columns to keep,rest have too many nulls\n",
    "DF = DF[colsToKeep].copy() \n",
    "print(DF.isnull().sum().to_numpy())\n",
    "print(colsToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Nulls\n",
    "def RemoveNulls(TheDF):\n",
    "   print('Removing Nulls...')\n",
    "   for col in TheDF.columns:\n",
    "      for x in TheDF[TheDF[col].isnull()].index: #Going through all columns\n",
    "         beds = TheDF.loc[x]['Bedrooms']\n",
    "         state = TheDF.loc[x]['State']\n",
    "         #print)\n",
    "         if(isBedStateOptimized == True):\n",
    "            valFill = TheDF[(TheDF['Bedrooms'] == beds) & (TheDF['State']==state)][col] #Bedroom and state\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill = TheDF[(TheDF['Bedrooms'] == beds)][col] #Check if we can do only with bedroom as this is more correlated than state\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill = TheDF[(TheDF['State'] == beds)][col] #If only bedrooms didnt work, try with State\n",
    "            if np.all(np.isnan(valFill)):\n",
    "               valFill =TheDF[col] #If we get null for those too..just take median of whole column\n",
    "            valFill = np.nanmedian(valFill)\n",
    "            TheDF.loc[x,col] = valFill\n",
    "         else:\n",
    "            valFill =TheDF[col]\n",
    "            valFill = np.nanmedian(valFill)\n",
    "            TheDF.loc[x,col] = valFill\n",
    "   print('Nulls Removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removing Nulls...\n",
      "Nulls Removed.\n"
     ]
    }
   ],
   "source": [
    "RemoveNulls(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      BedroomsSq    RegionName State                                  Metro  \\\n",
       "0              2   Springfield    OH                            Springfield   \n",
       "1              4  Simpsonville    SC            Greenville-Anderson-Mauldin   \n",
       "2              2      Cranston    RI                     Providence-Warwick   \n",
       "3              1   Kansas City    KS                            Kansas City   \n",
       "4              4     Riverview    FL        Tampa-St. Petersburg-Clearwater   \n",
       "...          ...           ...   ...                                    ...   \n",
       "3384           2    Shrewsbury    MA                              Worcester   \n",
       "3385           1      Surfside    FL  Miami-Fort Lauderdale-West Palm Beach   \n",
       "3386           1    Brookfield    WI          Milwaukee-Waukesha-West Allis   \n",
       "3387           1        Dedham    MA                Boston-Cambridge-Newton   \n",
       "3388           1       Wyoming    MI                   Grand Rapids-Wyoming   \n",
       "\n",
       "               CountyName  Bedrooms  2017-08  2017-09  2017-10  2017-11  ...  \\\n",
       "0            Clark County         2   827.50   860.00    812.5    850.0  ...   \n",
       "1       Greenville County         4  1750.00  1725.00   1695.0   1650.0  ...   \n",
       "2       Providence County         2  1300.00  1300.00   1250.0   1100.0  ...   \n",
       "3        Wyandotte County         1   918.00   895.00    917.5    890.0  ...   \n",
       "4     Hillsborough County         4  1650.00  1675.00   1612.5   1599.0  ...   \n",
       "...                   ...       ...      ...      ...      ...      ...  ...   \n",
       "3384     Worcester County         2  2000.00  1975.00   1971.0   1987.5  ...   \n",
       "3385    Miami-Dade County         1  1825.00  1800.00   1800.0   1800.0  ...   \n",
       "3386      Waukesha County         1   921.25   875.00    860.0    887.5  ...   \n",
       "3387       Norfolk County         1  1767.25  1777.50   1750.0   1728.5  ...   \n",
       "3388          Kent County         1  1049.25  1028.75   1037.5    991.0  ...   \n",
       "\n",
       "      2019-03  2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  2019-10  \\\n",
       "0       665.0    685.0    714.0    714.0    685.0    695.0    697.5    675.0   \n",
       "1      1812.5   1770.0   1795.0   1795.0   1795.0   1695.0   1650.0   1695.0   \n",
       "2      1397.5   1397.5   1300.0   1200.0   1300.0   1350.0   1300.0   1300.0   \n",
       "3       830.5    863.0    747.0    744.0    785.0    735.0    705.0    785.0   \n",
       "4      1712.5   1750.0   1750.0   1750.0   1750.0   1750.0   1760.0   1750.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3384   1790.5   1890.0   1699.0   1727.5   1699.0   1725.0   1857.0   1867.0   \n",
       "3385   1875.0   1850.0   1750.0   1800.0   1800.0   1750.0   1750.0   1800.0   \n",
       "3386   1385.0   1385.0   1386.0   1386.0   1395.0   1405.0   1365.0   1395.0   \n",
       "3387   2392.5   2345.0   2347.5   2347.5   2343.5   2433.0   2334.5   1985.0   \n",
       "3388    828.5    838.0    844.0    858.0    876.5    891.0    882.0    884.5   \n",
       "\n",
       "      2019-11  2019-12  \n",
       "0       650.0    675.0  \n",
       "1      1800.0   1850.0  \n",
       "2      1200.0   1250.0  \n",
       "3       747.5    695.0  \n",
       "4      1752.5   1745.0  \n",
       "...       ...      ...  \n",
       "3384   1701.5   1762.0  \n",
       "3385   1800.0   1850.0  \n",
       "3386   1395.0   1395.0  \n",
       "3387   1950.0   1725.0  \n",
       "3388    869.0    924.0  \n",
       "\n",
       "[3389 rows x 35 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BedroomsSq</th>\n      <th>RegionName</th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>Bedrooms</th>\n      <th>2017-08</th>\n      <th>2017-09</th>\n      <th>2017-10</th>\n      <th>2017-11</th>\n      <th>...</th>\n      <th>2019-03</th>\n      <th>2019-04</th>\n      <th>2019-05</th>\n      <th>2019-06</th>\n      <th>2019-07</th>\n      <th>2019-08</th>\n      <th>2019-09</th>\n      <th>2019-10</th>\n      <th>2019-11</th>\n      <th>2019-12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>827.50</td>\n      <td>860.00</td>\n      <td>812.5</td>\n      <td>850.0</td>\n      <td>...</td>\n      <td>665.0</td>\n      <td>685.0</td>\n      <td>714.0</td>\n      <td>714.0</td>\n      <td>685.0</td>\n      <td>695.0</td>\n      <td>697.5</td>\n      <td>675.0</td>\n      <td>650.0</td>\n      <td>675.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Simpsonville</td>\n      <td>SC</td>\n      <td>Greenville-Anderson-Mauldin</td>\n      <td>Greenville County</td>\n      <td>4</td>\n      <td>1750.00</td>\n      <td>1725.00</td>\n      <td>1695.0</td>\n      <td>1650.0</td>\n      <td>...</td>\n      <td>1812.5</td>\n      <td>1770.0</td>\n      <td>1795.0</td>\n      <td>1795.0</td>\n      <td>1795.0</td>\n      <td>1695.0</td>\n      <td>1650.0</td>\n      <td>1695.0</td>\n      <td>1800.0</td>\n      <td>1850.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Cranston</td>\n      <td>RI</td>\n      <td>Providence-Warwick</td>\n      <td>Providence County</td>\n      <td>2</td>\n      <td>1300.00</td>\n      <td>1300.00</td>\n      <td>1250.0</td>\n      <td>1100.0</td>\n      <td>...</td>\n      <td>1397.5</td>\n      <td>1397.5</td>\n      <td>1300.0</td>\n      <td>1200.0</td>\n      <td>1300.0</td>\n      <td>1350.0</td>\n      <td>1300.0</td>\n      <td>1300.0</td>\n      <td>1200.0</td>\n      <td>1250.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Kansas City</td>\n      <td>KS</td>\n      <td>Kansas City</td>\n      <td>Wyandotte County</td>\n      <td>1</td>\n      <td>918.00</td>\n      <td>895.00</td>\n      <td>917.5</td>\n      <td>890.0</td>\n      <td>...</td>\n      <td>830.5</td>\n      <td>863.0</td>\n      <td>747.0</td>\n      <td>744.0</td>\n      <td>785.0</td>\n      <td>735.0</td>\n      <td>705.0</td>\n      <td>785.0</td>\n      <td>747.5</td>\n      <td>695.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Riverview</td>\n      <td>FL</td>\n      <td>Tampa-St. Petersburg-Clearwater</td>\n      <td>Hillsborough County</td>\n      <td>4</td>\n      <td>1650.00</td>\n      <td>1675.00</td>\n      <td>1612.5</td>\n      <td>1599.0</td>\n      <td>...</td>\n      <td>1712.5</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1760.0</td>\n      <td>1750.0</td>\n      <td>1752.5</td>\n      <td>1745.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>2</td>\n      <td>Shrewsbury</td>\n      <td>MA</td>\n      <td>Worcester</td>\n      <td>Worcester County</td>\n      <td>2</td>\n      <td>2000.00</td>\n      <td>1975.00</td>\n      <td>1971.0</td>\n      <td>1987.5</td>\n      <td>...</td>\n      <td>1790.5</td>\n      <td>1890.0</td>\n      <td>1699.0</td>\n      <td>1727.5</td>\n      <td>1699.0</td>\n      <td>1725.0</td>\n      <td>1857.0</td>\n      <td>1867.0</td>\n      <td>1701.5</td>\n      <td>1762.0</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>1</td>\n      <td>Surfside</td>\n      <td>FL</td>\n      <td>Miami-Fort Lauderdale-West Palm Beach</td>\n      <td>Miami-Dade County</td>\n      <td>1</td>\n      <td>1825.00</td>\n      <td>1800.00</td>\n      <td>1800.0</td>\n      <td>1800.0</td>\n      <td>...</td>\n      <td>1875.0</td>\n      <td>1850.0</td>\n      <td>1750.0</td>\n      <td>1800.0</td>\n      <td>1800.0</td>\n      <td>1750.0</td>\n      <td>1750.0</td>\n      <td>1800.0</td>\n      <td>1800.0</td>\n      <td>1850.0</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>1</td>\n      <td>Brookfield</td>\n      <td>WI</td>\n      <td>Milwaukee-Waukesha-West Allis</td>\n      <td>Waukesha County</td>\n      <td>1</td>\n      <td>921.25</td>\n      <td>875.00</td>\n      <td>860.0</td>\n      <td>887.5</td>\n      <td>...</td>\n      <td>1385.0</td>\n      <td>1385.0</td>\n      <td>1386.0</td>\n      <td>1386.0</td>\n      <td>1395.0</td>\n      <td>1405.0</td>\n      <td>1365.0</td>\n      <td>1395.0</td>\n      <td>1395.0</td>\n      <td>1395.0</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>1</td>\n      <td>Dedham</td>\n      <td>MA</td>\n      <td>Boston-Cambridge-Newton</td>\n      <td>Norfolk County</td>\n      <td>1</td>\n      <td>1767.25</td>\n      <td>1777.50</td>\n      <td>1750.0</td>\n      <td>1728.5</td>\n      <td>...</td>\n      <td>2392.5</td>\n      <td>2345.0</td>\n      <td>2347.5</td>\n      <td>2347.5</td>\n      <td>2343.5</td>\n      <td>2433.0</td>\n      <td>2334.5</td>\n      <td>1985.0</td>\n      <td>1950.0</td>\n      <td>1725.0</td>\n    </tr>\n    <tr>\n      <th>3388</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>1049.25</td>\n      <td>1028.75</td>\n      <td>1037.5</td>\n      <td>991.0</td>\n      <td>...</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n      <td>858.0</td>\n      <td>876.5</td>\n      <td>891.0</td>\n      <td>882.0</td>\n      <td>884.5</td>\n      <td>869.0</td>\n      <td>924.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3389 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed Last Column is Target, it should return Xtrain,Ytrain,Xtest,Ytest\n",
    "def ChangeDataSetForTimeSeries(TheDF):\n",
    "    posOfFirstDate = np.where(TheDF.columns=='Bedrooms')[0][0] + 1\n",
    "    FirstDate = TheDF.columns[posOfFirstDate]\n",
    "    T = 10\n",
    "    Startindex = np.where(TheDF.columns==FirstDate)[0][0]\n",
    "    #print(TheDF.columns[Startindex])\n",
    "    TrainEndindex = TheDF.columns.size-3\n",
    "    #ValidationEndindex = TheDF.columns.size-3\n",
    "    TestEndindex = TheDF.columns.size-2\n",
    "    #print(TheDF.columns[TrainEndindex])\n",
    "    size = TrainEndindex - Startindex + 1\n",
    "    colListTrain = TheDF.columns[0:Startindex].tolist()\n",
    "    for i in range(T):\n",
    "        colListTrain.append('T'+str(i))\n",
    "    TrainDFX = pd.DataFrame(columns=colListTrain[:-1])\n",
    "    TrainDFY = pd.DataFrame(columns=['T'+str(T)])\n",
    "    #print(colListTrain,len(colListTrain))\n",
    "    #Make Train-------------------------------\n",
    "    X_Arr = []\n",
    "    Y_Arr = []\n",
    "    for i in range(len(TheDF.index)): #Row Iteration\n",
    "        if(i%25==0):\n",
    "            print('\\r', 'Iteration', i+1, ' / Rows:', len(TheDF.index), end='')\n",
    "        initdataToInsert = TheDF.iloc[i,0:Startindex].to_numpy().tolist()\n",
    "        #print('-')\n",
    "        #print(initdataToInsert)\n",
    "        #print('-')\n",
    "        for t in range(Startindex,TrainEndindex + 1 - T):\n",
    "            x = TheDF.iloc[i,t:t+T].to_numpy().tolist()\n",
    "            #print(x)\n",
    "            #x = np.concatenate((initdataToInsert,x))\n",
    "            X_Arr.extend(initdataToInsert)\n",
    "            X_Arr.extend(x)\n",
    "            y = TheDF.iloc[i,t+T]\n",
    "            Y_Arr.append(y)\n",
    "            #return X_Arr,Y_Arr\n",
    "        # X_Arr = np.array(X_Arr).reshape(-1,len(colListTrain))\n",
    "        # Y_Arr = np.array(Y_Arr).reshape(-1,1)\n",
    "        \n",
    "        # X_Arr = pd.DataFrame(X_Arr,columns=colListTrain).to_dict()\n",
    "        # Y_Arr = pd.DataFrame(Y_Arr,columns=['T10'])\n",
    "        # #print(X_Arr)\n",
    "        # TrainDFX = TrainDFX.append(X_Arr,ignore_index=True)\n",
    "        # TrainDFY = TrainDFY.append(Y_Arr,ignore_index=True)\n",
    "        #break\n",
    "        #return TrainDFX,TrainDFY\n",
    "        #for ind in ():\n",
    "            #print(X)\n",
    "            #FinalDFX.loc[ind] = X[:,ind]\n",
    "            #FinalDFY.loc[ind] = Y.reshape(-1,1)\n",
    "            #break\n",
    "        #break   \n",
    "    print('\\r', 'Iteration', i+1, ' / Rows:', len(TheDF.index), end='') \n",
    "    X_Arr = np.array(X_Arr).reshape(-1,len(colListTrain))\n",
    "    Y_Arr = np.array(Y_Arr).reshape(-1,1)\n",
    "    \n",
    "    X_Arr = pd.DataFrame(X_Arr,columns=colListTrain)\n",
    "    Y_Arr = pd.DataFrame(Y_Arr,columns=['T10'])\n",
    "    #print(X_Arr)\n",
    "    TrainDFX = TrainDFX.append(X_Arr,ignore_index=True)\n",
    "    TrainDFY = TrainDFY.append(Y_Arr,ignore_index=True)\n",
    "    #Training Sets Done!!!!!\n",
    "    testColNames = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    #valColData = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    testColData = TheDF.columns[0:Startindex].to_numpy().tolist()\n",
    "    for i in range(T):\n",
    "        testColNames.append('T'+str(i))\n",
    "        #valColData.extend([TheDF.columns[ValidationEndindex-T+i+1]])\n",
    "        testColData.extend([TheDF.columns[TestEndindex-T+i+1]])\n",
    "    #Get Data of Validation and Testing.\n",
    "    print('----')\n",
    "    #print(valColData,testColData)\n",
    "    #ValDFX = TheDF[valColData].copy()\n",
    "    #ValDFX.columns = valAndTestColNames\n",
    "    #ValDFY = TheDF.iloc[:,ValidationEndindex+1].copy()\n",
    "    #ValDFY.columns = 'T'+str(T)\n",
    "    # ValidationEndindex\n",
    "    TestDFX = TheDF[testColData].copy()\n",
    "    TestDFX.columns = testColNames\n",
    "    TestDFY = TheDF.iloc[:,TestEndindex+1].copy()\n",
    "    TestDFY.columns = 'T'+str(T)\n",
    "    #return TrainDFX,TrainDFY,ValDFX,ValDFY,TestDFX,TestDFY\n",
    "    return TrainDFX,TrainDFY,TestDFX,TestDFY\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Iteration 3389  / Rows: 3389----\n"
     ]
    }
   ],
   "source": [
    "TrainDFX,TrainDFY,TestDFX,TestDFY = ChangeDataSetForTimeSeries(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      BedroomsSq   RegionName State                 Metro    CountyName  \\\n",
       "0              2  Springfield    OH           Springfield  Clark County   \n",
       "1              2  Springfield    OH           Springfield  Clark County   \n",
       "2              2  Springfield    OH           Springfield  Clark County   \n",
       "3              2  Springfield    OH           Springfield  Clark County   \n",
       "4              2  Springfield    OH           Springfield  Clark County   \n",
       "...          ...          ...   ...                   ...           ...   \n",
       "57608          1      Wyoming    MI  Grand Rapids-Wyoming   Kent County   \n",
       "57609          1      Wyoming    MI  Grand Rapids-Wyoming   Kent County   \n",
       "57610          1      Wyoming    MI  Grand Rapids-Wyoming   Kent County   \n",
       "57611          1      Wyoming    MI  Grand Rapids-Wyoming   Kent County   \n",
       "57612          1      Wyoming    MI  Grand Rapids-Wyoming   Kent County   \n",
       "\n",
       "      Bedrooms     T0     T1     T2     T3     T4     T5     T6     T7     T8  \\\n",
       "0            2  827.5  860.0  812.5  850.0  867.5  875.0  875.0  900.0  877.5   \n",
       "1            2  860.0  812.5  850.0  867.5  875.0  875.0  900.0  877.5  900.0   \n",
       "2            2  812.5  850.0  867.5  875.0  875.0  900.0  877.5  900.0  890.0   \n",
       "3            2  850.0  867.5  875.0  875.0  900.0  877.5  900.0  890.0  600.0   \n",
       "4            2  867.5  875.0  875.0  900.0  877.5  900.0  890.0  600.0  600.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "57608        1  995.0  962.5  831.0  849.0  832.0  847.5  821.0  828.5  838.0   \n",
       "57609        1  962.5  831.0  849.0  832.0  847.5  821.0  828.5  838.0  844.0   \n",
       "57610        1  831.0  849.0  832.0  847.5  821.0  828.5  838.0  844.0  858.0   \n",
       "57611        1  849.0  832.0  847.5  821.0  828.5  838.0  844.0  858.0  876.5   \n",
       "57612        1  832.0  847.5  821.0  828.5  838.0  844.0  858.0  876.5  891.0   \n",
       "\n",
       "          T9  \n",
       "0      900.0  \n",
       "1      890.0  \n",
       "2      600.0  \n",
       "3      600.0  \n",
       "4      612.5  \n",
       "...      ...  \n",
       "57608  844.0  \n",
       "57609  858.0  \n",
       "57610  876.5  \n",
       "57611  891.0  \n",
       "57612  882.0  \n",
       "\n",
       "[57613 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BedroomsSq</th>\n      <th>RegionName</th>\n      <th>State</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>Bedrooms</th>\n      <th>T0</th>\n      <th>T1</th>\n      <th>T2</th>\n      <th>T3</th>\n      <th>T4</th>\n      <th>T5</th>\n      <th>T6</th>\n      <th>T7</th>\n      <th>T8</th>\n      <th>T9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>827.5</td>\n      <td>860.0</td>\n      <td>812.5</td>\n      <td>850.0</td>\n      <td>867.5</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>900.0</td>\n      <td>877.5</td>\n      <td>900.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>860.0</td>\n      <td>812.5</td>\n      <td>850.0</td>\n      <td>867.5</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>900.0</td>\n      <td>877.5</td>\n      <td>900.0</td>\n      <td>890.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>812.5</td>\n      <td>850.0</td>\n      <td>867.5</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>900.0</td>\n      <td>877.5</td>\n      <td>900.0</td>\n      <td>890.0</td>\n      <td>600.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>850.0</td>\n      <td>867.5</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>900.0</td>\n      <td>877.5</td>\n      <td>900.0</td>\n      <td>890.0</td>\n      <td>600.0</td>\n      <td>600.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Springfield</td>\n      <td>OH</td>\n      <td>Springfield</td>\n      <td>Clark County</td>\n      <td>2</td>\n      <td>867.5</td>\n      <td>875.0</td>\n      <td>875.0</td>\n      <td>900.0</td>\n      <td>877.5</td>\n      <td>900.0</td>\n      <td>890.0</td>\n      <td>600.0</td>\n      <td>600.0</td>\n      <td>612.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57608</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>995.0</td>\n      <td>962.5</td>\n      <td>831.0</td>\n      <td>849.0</td>\n      <td>832.0</td>\n      <td>847.5</td>\n      <td>821.0</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n    </tr>\n    <tr>\n      <th>57609</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>962.5</td>\n      <td>831.0</td>\n      <td>849.0</td>\n      <td>832.0</td>\n      <td>847.5</td>\n      <td>821.0</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n      <td>858.0</td>\n    </tr>\n    <tr>\n      <th>57610</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>831.0</td>\n      <td>849.0</td>\n      <td>832.0</td>\n      <td>847.5</td>\n      <td>821.0</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n      <td>858.0</td>\n      <td>876.5</td>\n    </tr>\n    <tr>\n      <th>57611</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>849.0</td>\n      <td>832.0</td>\n      <td>847.5</td>\n      <td>821.0</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n      <td>858.0</td>\n      <td>876.5</td>\n      <td>891.0</td>\n    </tr>\n    <tr>\n      <th>57612</th>\n      <td>1</td>\n      <td>Wyoming</td>\n      <td>MI</td>\n      <td>Grand Rapids-Wyoming</td>\n      <td>Kent County</td>\n      <td>1</td>\n      <td>832.0</td>\n      <td>847.5</td>\n      <td>821.0</td>\n      <td>828.5</td>\n      <td>838.0</td>\n      <td>844.0</td>\n      <td>858.0</td>\n      <td>876.5</td>\n      <td>891.0</td>\n      <td>882.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57613 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "TrainDFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found out Bedroom was more correlated than these and then on 2nd place is State\n",
    "# TrainDF['RegionName'] = lb.fit_transform(TrainDF['RegionName'])\n",
    "# TrainDF['State'] = lb.fit_transform(TrainDF['State'])\n",
    "# TrainDF['Metro'] = lb.fit_transform(TrainDF['Metro'])\n",
    "# TrainDF['CountyName'] = lb.fit_transform(TrainDF['CountyName'])\n",
    "#TrainDF['State'] = lb.fit_transform(TrainDF['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainDF.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "balanced-greensboro",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Pass by Value Reference Magic!\n",
    "def AddStateSparseMatrix(TrainingDF):\n",
    "   enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "   SM = enc.fit_transform(TrainingDF['State'].to_numpy().reshape(-1,1))\n",
    "   for ind,cat in zip(range(0,len(enc.categories_[0])),enc.categories_[0]):\n",
    "      TrainingDF.insert(0,'is'+str(cat),SM[:,ind])\n",
    "   TrainingDF.drop(columns=['State'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-shopper",
   "metadata": {},
   "source": [
    "### Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunAllModels(TrainDF,Output,title):\n",
    "    global runNo\n",
    "    global RecordAnalysisDF\n",
    "    global isBedStateOptimized\n",
    "    def PrintMetrics(scores,algo):\n",
    "        global RecordAnalysisDF\n",
    "        print('-'*5)\n",
    "        meanR2 = np.absolute(scores['test_r2']).mean()\n",
    "        medianR2 = np.median(np.absolute(scores['test_r2']))\n",
    "        meanRMSE = np.absolute(scores['test_neg_root_mean_squared_error']).mean()\n",
    "        medianRMSE = np.median(np.absolute(scores['test_neg_root_mean_squared_error']))\n",
    "        meanMAPE = np.absolute(scores['test_neg_mean_absolute_percentage_error']).mean()\n",
    "        medianMAPE = np.median(np.absolute(scores['test_neg_mean_absolute_percentage_error']))\n",
    "        print('Average R2 score ', meanR2)\n",
    "        print('Median R2 score ', medianR2)\n",
    "        print('Average Root Mean Square Error ', meanRMSE)\n",
    "        print('Median Root Mean Square Error ', medianRMSE)\n",
    "        print('-'*5)\n",
    "        if(isBedStateOptimized==False):\n",
    "            algo = algo + ' Nulls removed with complete column'\n",
    "        RecordAnalysisDF = RecordAnalysisDF.append({'RunNumber':runNo,'Title':title,'Algorithm':algo,'R2Mean':meanR2,'R2Median':medianR2,'RMSEMean':meanRMSE,'RMSEMedian':medianRMSE},ignore_index=True)\n",
    "        #print('Average Mean Absolute Percentage Error ', meanMAPE)\n",
    "        #print('Median Mean Absolute Percentage Error ', medianMAPE)\n",
    "    #-----------------------Linear Regression---------------------------------------------\n",
    "    print(title)\n",
    "    print('-'*10)\n",
    "    print('Linear Regression')\n",
    "    model = make_pipeline(StandardScaler(),LinearRegression())\n",
    "    # Y_pred = model.predict(X_test)\n",
    "    # Y_pred = scY.inverse_transform(Y_pred)\n",
    "    # Y_test = scY.inverse_transform(Y_test)\n",
    "    scores = cross_validate(model, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    PrintMetrics(scores,'Linear Regression')#,meanMAPE,medianMAPE)\n",
    "    #----------------------------Polynomial Lasso---------------------------------------\n",
    "    for _,degree in enumerate([1]):\n",
    "        polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Lasso(alpha=1e-2,max_iter=1e+6,tol=1e-2))\n",
    "        scores = cross_validate(polymodel, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "        print('Polynomial Degree with Lasso: '+str(degree))\n",
    "        PrintMetrics(scores,'Lasso Degree ' + str(degree))\n",
    "\n",
    "        polymodel = make_pipeline(StandardScaler(),PolynomialFeatures(degree),Ridge(alpha=1e-3,max_iter=1e+6))\n",
    "        scores = cross_validate(polymodel, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "        print('Polynomial Degree with Ridge: '+str(degree))\n",
    "        PrintMetrics(scores,'Ridge Degree ' + str(degree))\n",
    "    #----------------------------DecisionTreeRegressor---------------------------------------\n",
    "    model = make_pipeline(StandardScaler(),DecisionTreeRegressor(max_depth=100))\n",
    "    scores = cross_validate(model, TrainDF, Output, cv=15,scoring=('r2', 'neg_root_mean_squared_error','neg_mean_absolute_percentage_error'))\n",
    "    print('DecisionTreeRegressor')\n",
    "    PrintMetrics(scores,'DecisionTreeRegressor')\n",
    "    runNo = runNo + 1\n",
    "    print('-'*5)\n",
    "    print('-'*15)"
   ]
  },
  {
   "source": [
    "### Method 1: Drop all the Categorical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dropped Categorical Data\n",
      "----------\n",
      "Linear Regression\n",
      "-----\n",
      "Average R2 score  0.9849928561541622\n",
      "Median R2 score  0.9901707051212374\n",
      "Average Root Mean Square Error  158.0067710715298\n",
      "Median Root Mean Square Error  129.8187608731687\n",
      "-----\n",
      "Polynomial Degree with Lasso: 1\n",
      "-----\n",
      "Average R2 score  0.9790593644677237\n",
      "Median R2 score  0.9854730928991886\n",
      "Average Root Mean Square Error  182.03409840190267\n",
      "Median Root Mean Square Error  144.22921422235459\n",
      "-----\n",
      "Polynomial Degree with Ridge: 1\n",
      "-----\n",
      "Average R2 score  0.9849929479395059\n",
      "Median R2 score  0.9901709154924679\n",
      "Average Root Mean Square Error  158.00644804614336\n",
      "Median Root Mean Square Error  129.81746566475977\n",
      "-----\n",
      "DecisionTreeRegressor\n",
      "-----\n",
      "Average R2 score  0.9648915348262006\n",
      "Median R2 score  0.9774879678754967\n",
      "Average Root Mean Square Error  264.34587047411645\n",
      "Median Root Mean Square Error  182.82950249171918\n",
      "-----\n",
      "-----\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "# RemoveNulls(FinalTrainDF,True)\n",
    "FinalTrainDF.drop(columns=['State'],inplace=True)\n",
    "RunAllModels(FinalTrainDF,TrainDFY,'Dropped Categorical Data')"
   ]
  },
  {
   "source": [
    "### Method2: Next, Let's change States to a sparse matrix and then to 51 columns, 1 for each State. Lets drop the other categorical columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "One Hot Encoded State,Removed Others\n",
      "----------\n",
      "Linear Regression\n",
      "-----\n",
      "Average R2 score  0.985024411920578\n",
      "Median R2 score  0.9902466648840058\n",
      "Average Root Mean Square Error  157.93357695682107\n",
      "Median Root Mean Square Error  129.60280984773328\n",
      "-----\n",
      "Polynomial Degree with Lasso: 1\n",
      "-----\n",
      "Average R2 score  0.9790702934269788\n",
      "Median R2 score  0.9855457624388688\n",
      "Average Root Mean Square Error  182.05421950135653\n",
      "Median Root Mean Square Error  145.56754866994018\n",
      "-----\n",
      "Polynomial Degree with Ridge: 1\n",
      "-----\n",
      "Average R2 score  0.98502396890015\n",
      "Median R2 score  0.9902467230558996\n",
      "Average Root Mean Square Error  157.9353752887838\n",
      "Median Root Mean Square Error  129.6037279938246\n",
      "-----\n",
      "DecisionTreeRegressor\n",
      "-----\n",
      "Average R2 score  0.9629874241341022\n",
      "Median R2 score  0.9736511455051692\n",
      "Average Root Mean Square Error  282.72789781772536\n",
      "Median Root Mean Square Error  186.57353226144994\n",
      "-----\n",
      "-----\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#RemoveNulls(FinalTrainDF,True)\n",
    "AddStateSparseMatrix(FinalTrainDF)\n",
    "#FinalTrainDF.drop(columns=['State'],inplace=True)\n",
    "RunAllModels(FinalTrainDF,TrainDFY,'One Hot Encoded State,Removed Others')\n",
    "#FinalTrainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  RunNumber                                 Title              Algorithm  \\\n",
       "0         1              Dropped Categorical Data      Linear Regression   \n",
       "1         1              Dropped Categorical Data         Lasso Degree 1   \n",
       "2         1              Dropped Categorical Data         Ridge Degree 1   \n",
       "3         1              Dropped Categorical Data  DecisionTreeRegressor   \n",
       "4         2  One Hot Encoded State,Removed Others      Linear Regression   \n",
       "5         2  One Hot Encoded State,Removed Others         Lasso Degree 1   \n",
       "6         2  One Hot Encoded State,Removed Others         Ridge Degree 1   \n",
       "7         2  One Hot Encoded State,Removed Others  DecisionTreeRegressor   \n",
       "\n",
       "     R2Mean  R2Median    RMSEMean  RMSEMedian  \n",
       "0  0.984993  0.990171  158.006771  129.818761  \n",
       "1  0.979059  0.985473  182.034098  144.229214  \n",
       "2  0.984993  0.990171  158.006448  129.817466  \n",
       "3  0.964892  0.977488  264.345870  182.829502  \n",
       "4  0.985024  0.990247  157.933577  129.602810  \n",
       "5  0.979070  0.985546  182.054220  145.567549  \n",
       "6  0.985024  0.990247  157.935375  129.603728  \n",
       "7  0.962987  0.973651  282.727898  186.573532  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RunNumber</th>\n      <th>Title</th>\n      <th>Algorithm</th>\n      <th>R2Mean</th>\n      <th>R2Median</th>\n      <th>RMSEMean</th>\n      <th>RMSEMedian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>Linear Regression</td>\n      <td>0.984993</td>\n      <td>0.990171</td>\n      <td>158.006771</td>\n      <td>129.818761</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>Lasso Degree 1</td>\n      <td>0.979059</td>\n      <td>0.985473</td>\n      <td>182.034098</td>\n      <td>144.229214</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>Ridge Degree 1</td>\n      <td>0.984993</td>\n      <td>0.990171</td>\n      <td>158.006448</td>\n      <td>129.817466</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Dropped Categorical Data</td>\n      <td>DecisionTreeRegressor</td>\n      <td>0.964892</td>\n      <td>0.977488</td>\n      <td>264.345870</td>\n      <td>182.829502</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>Linear Regression</td>\n      <td>0.985024</td>\n      <td>0.990247</td>\n      <td>157.933577</td>\n      <td>129.602810</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>Lasso Degree 1</td>\n      <td>0.979070</td>\n      <td>0.985546</td>\n      <td>182.054220</td>\n      <td>145.567549</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>Ridge Degree 1</td>\n      <td>0.985024</td>\n      <td>0.990247</td>\n      <td>157.935375</td>\n      <td>129.603728</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>One Hot Encoded State,Removed Others</td>\n      <td>DecisionTreeRegressor</td>\n      <td>0.962987</td>\n      <td>0.973651</td>\n      <td>282.727898</td>\n      <td>186.573532</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "RecordAnalysisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF.index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordAnalysisDF.to_csv('RecordAnalysis.csv',index_label='S.No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Analyzing this CSV File (Copy of the table is in the report), we found that \"One Hot Encoded State,Removed Others - NAN removed with column with Linear Regression\" had the least R2Mean and RMSE Median. So, it had performed best in the 2/4 metrics we considered. Hence, we decided to go ahead with it."
   ]
  },
  {
   "source": [
    "### Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoded State,Removed Others\tLinear Regression\n",
    "FinalTrainDF = TrainDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#RemoveNulls(FinalTrainDF,True)\n",
    "AddStateSparseMatrix(FinalTrainDF)\n",
    "FinalTestDF = TestDFX.drop(columns=['RegionName', 'Metro', 'CountyName'])\n",
    "#FinalTrainDF[ValDF.name] = ValDF\n",
    "#RemoveNulls(FinalTrainDF,False)\n",
    "AddStateSparseMatrix(FinalTestDF)\n",
    "#FinalTrainDF.drop(columns=['State'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "hist = model.fit(FinalTrainDF,TrainDFY)\n",
    "YPred = model.predict(FinalTestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 score  0.9944659122041594\nRoot Mean Square Error  136.35425137459862\nAverage of Output  1779.1479787547948\n"
     ]
    }
   ],
   "source": [
    "R2Score = r2score(TestDFY,YPred)\n",
    "RMSE = mse(TestDFY,YPred,squared=False)\n",
    "print('R2 score ', R2Score)\n",
    "print('Root Mean Square Error ', RMSE)\n",
    "print('Average of Output ',TestDFY.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.07664163996013168"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "136.356818823521/1779.1479787547948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
       "       'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
       "       'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
       "       'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
       "       'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For 1 bedrooms\n-----\nR2 score  0.9913823818975729\nRoot Mean Square Error  49.12731717848224\nAverage of 1 Bedroom Cost  1384.4834963325184\nNumber of Houses  818\n----------\nFor 2 bedrooms\n-----\nR2 score  0.9922284242596486\nRoot Mean Square Error  59.51218426454646\nAverage of 2 Bedroom Cost  1566.38814229249\nNumber of Houses  1265\n----------\nFor 3 bedrooms\n-----\nR2 score  0.996303893085298\nRoot Mean Square Error  96.80884066962692\nAverage of 3 Bedroom Cost  1969.8116161616163\nNumber of Houses  990\n----------\nFor 4 bedrooms\n-----\nR2 score  0.9935543538200522\nRoot Mean Square Error  386.7963223920657\nAverage of 4 Bedroom Cost  3055.159810126582\nNumber of Houses  316\n----------\n"
     ]
    }
   ],
   "source": [
    "for bed in range(1,5):\n",
    "    filterArr = (FinalTestDF['Bedrooms'] == bed)\n",
    "    #print(filterArr)\n",
    "    print('For '+ str(bed) +' bedrooms')\n",
    "    print('-'*5)\n",
    "    R2Score = r2score(TestDFY[filterArr],YPred[filterArr])\n",
    "    RMSE = mse(TestDFY[filterArr],YPred[filterArr],squared=False)\n",
    "    print('R2 score ', R2Score)\n",
    "    print('Root Mean Square Error ', RMSE)\n",
    "    print('Average of '+ str(bed) +' Bedroom Cost ',TestDFY[filterArr].mean())\n",
    "    print('Number of Houses ',len(TestDFY[filterArr].index))\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}